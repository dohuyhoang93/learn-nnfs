{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#codex-neuralis-genesis-hanh-trinh-kien-tao-mang-no-ron-tu-cot-loi","title":"\ud83d\ude80 Codex: Neuralis Genesis - H\u00e0nh Tr\u00ecnh Ki\u1ebfn T\u1ea1o M\u1ea1ng N\u01a1-ron t\u1eeb C\u1ed1t L\u00f5i","text":"<p>[Ghi Ch\u00e9p L\u01b0u Tr\u1eef t\u1eeb D\u1ef1 \u00c1n H\u1ecdc T\u1eadp \"Neural Networks from Scratch in Python\"]</p> <p>\u201cTrong v\u0169 tr\u1ee5 c\u1ee7a d\u1eef li\u1ec7u, n\u01a1i th\u00f4ng tin l\u00e0 d\u00f2ng ch\u1ea3y n\u0103ng l\u01b0\u1ee3ng v\u00f4 t\u1eadn, ch\u00fang ta kh\u00f4ng ch\u1ec9 l\u00e0 ng\u01b0\u1eddi l\u1eadp tr\u00ecnh. Ch\u00fang ta l\u00e0 nh\u1eefng Ki\u1ebfn Tr\u00fac S\u01b0 c\u1ee7a \u00dd Th\u1ee9c S\u1ed1.\u201d</p>"},{"location":"#tong-quan-nhiem-vu-project-directive","title":"\ud83c\udf0c T\u1ed4NG QUAN NHI\u1ec6M V\u1ee4 (PROJECT DIRECTIVE)","text":"<p>Ch\u00e0o m\u1eebng, L\u1eef kh\u00e1ch c\u1ee7a D\u00f2ng D\u1eef li\u1ec7u, \u0111\u1ebfn v\u1edbi kho l\u01b0u tr\u1eef Neuralis Genesis. \u0110\u00e2y kh\u00f4ng ch\u1ec9 l\u00e0 m\u1ed9t repo code th\u00f4ng th\u01b0\u1eddng. \u0110\u00e2y l\u00e0 nh\u1eadt k\u00fd h\u00e0nh tr\u00ecnh, l\u00e0 b\u1ea3n thi\u1ebft k\u1ebf chi ti\u1ebft ghi l\u1ea1i qu\u00e1 tr\u00ecnh t\u00f4i gi\u1ea3i m\u00e3 v\u00e0 t\u00e1i t\u1ea1o m\u1ed9t trong nh\u1eefng c\u1ea5u tr\u00fac k\u1ef3 di\u1ec7u nh\u1ea5t c\u1ee7a v\u0169 tr\u1ee5 s\u1ed1: M\u1ea1ng N\u01a1-ron Nh\u00e2n t\u1ea1o.</p> <p>D\u1ef1 \u00e1n n\u00e0y l\u00e0 h\u00e0nh tr\u00ecnh \u0111i s\u00e2u v\u00e0o \"h\u1ed9p \u0111en\", bi\u1ebfn nh\u1eefng kh\u00e1i ni\u1ec7m tr\u1eebu t\u01b0\u1ee3ng c\u1ee7a machine learning th\u00e0nh nh\u1eefng d\u00f2ng code Python h\u1eefu h\u00ecnh, d\u1ec5 hi\u1ec3u. M\u1ed7i commit l\u00e0 m\u1ed9t b\u01b0\u1edbc ti\u1ebfn, m\u1ed7i th\u01b0 m\u1ee5c l\u00e0 m\u1ed9t t\u1ea7ng nh\u1eadn th\u1ee9c m\u1edbi \u0111\u01b0\u1ee3c khai ph\u00e1, tu\u00e2n theo l\u1ed9 tr\u00ecnh c\u1ee7a cu\u1ed1n s\u00e1ch kinh \u0111i\u1ec3n:</p> <p>\ud83d\udcd6 Ngu\u1ed3n Tri Th\u1ee9c G\u1ed1c (The Prime Codex): Neural Networks from Scratch in Python by Harrison Kinsley &amp; Daniel Kukie\u0142a</p>"},{"location":"#kho-vu-khi-the-arsenal","title":"\ud83d\udee0\ufe0f KHO V\u0168 KH\u00cd (THE ARSENAL)","text":"<p>\u0110\u1ec3 ki\u1ebfn t\u1ea1o n\u00ean nh\u1eefng th\u1ef1c th\u1ec3 s\u1ed1 n\u00e0y, ch\u00fang ta c\u1ea7n m\u1ed9t b\u1ed9 c\u00f4ng c\u1ee5 t\u1ed1i t\u00e2n v\u00e0 \u0111\u00e1ng tin c\u1eady. D\u01b0\u1edbi \u0111\u00e2y l\u00e0 nh\u1eefng c\u00f4ng ngh\u1ec7 c\u1ed1t l\u00f5i \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong d\u1ef1 \u00e1n:</p> <p> </p>"},{"location":"#cau-truc-kho-luu-tru-archive-structure","title":"\ud83d\uddfa\ufe0f C\u1ea4U TR\u00daC KHO L\u01afU TR\u1eee (ARCHIVE STRUCTURE)","text":"<p>\u0110\u1ec3 \u0111\u1ea3m b\u1ea3o t\u00ednh khoa h\u1ecdc v\u00e0 d\u1ec5 d\u00e0ng truy xu\u1ea5t, to\u00e0n b\u1ed9 kho l\u01b0u tr\u1eef \u0111\u01b0\u1ee3c t\u1ed5 ch\u1ee9c theo c\u1ea5u tr\u00fac module, t\u01b0\u01a1ng \u1ee9ng v\u1edbi t\u1eebng ch\u01b0\u01a1ng trong s\u00e1ch.</p> Text Only<pre><code>NNFS-Codex/\n\u2502\n\u251c\u2500\u2500 Chapter_01_Gi\u1edbi_thi\u1ec7u/\n\u2502   \u251c\u2500\u2500 notes.md          # Ghi ch\u00fa, gi\u1ea3i th\u00edch chi ti\u1ebft d\u01b0\u1edbi d\u1ea1ng markdown\n\u2502   \u2514\u2500\u2500 practice.py       # M\u00e3 ngu\u1ed3n th\u1ef1c h\u00e0nh cho ch\u01b0\u01a1ng\n\u2502\n\u251c\u2500\u2500 Chapter_02_N\u01a1-ron_\u0111\u1ea7u_ti\u00ean/\n\u2502   \u251c\u2500\u2500 notes.md\n\u2502   \u2514\u2500\u2500 practice.py\n\u2502\n\u251c\u2500\u2500 Chapter_03_Th\u00eam_c\u00e1c_l\u1edbp/\n\u2502   \u251c\u2500\u2500 notes.md\n\u2502   \u2514\u2500\u2500 practice.py\n\u2502\n... (C\u00e1c module ti\u1ebfp theo)\n\u2502\n\u2514\u2500\u2500 README.md             # B\u1ea3n tuy\u00ean ng\u00f4n n\u00e0y\n</code></pre>"},{"location":"#nhat-ky-hanh-trinh-mission-log","title":"\ud83d\udcc8 NH\u1eacT K\u00dd H\u00c0NH TR\u00ccNH (MISSION LOG)","text":"<p>\u0110\u00e2y l\u00e0 b\u1ea3ng \u0111i\u1ec1u khi\u1ec3n trung t\u00e2m, theo d\u00f5i ti\u1ebfn \u0111\u1ed9 c\u1ee7a to\u00e0n b\u1ed9 nhi\u1ec7m v\u1ee5.</p> Ch\u01b0\u01a1ng / Module N\u1ed9i Dung Ch\u00ednh (Core Concepts) Tr\u1ea1ng Th\u00e1i Li\u00ean K\u1ebft Nhanh 01 Gi\u1edbi thi\u1ec7u &amp; Thi\u1ebft l\u1eadp M\u00f4i tr\u01b0\u1eddng \ud83d\udfe2 Ho\u00e0n th\u00e0nh <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 02 N\u01a1-ron &amp; L\u1edbp N\u01a1-ron \u0110\u1ea7u ti\u00ean \ud83d\udfe2 Ho\u00e0n th\u00e0nh <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 03 H\u00e0m M\u1ea5t m\u00e1t (Loss Function) \ud83d\udfe1 \u0110ang ti\u1ebfn h\u00e0nh <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 04 H\u00e0m K\u00edch ho\u1ea1t (Activation Functions) \ud83d\udfe2 Ho\u00e0n th\u00e0nh <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 05 T\u00ednh to\u00e1n H\u00e0m M\u1ea5t m\u00e1t \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 06 T\u1ed1i \u01b0u h\u00f3a (Optimization) \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 07 Lan truy\u1ec1n ng\u01b0\u1ee3c (Backpropagation) \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 08 C\u00e0i \u0111\u1eb7t Lan truy\u1ec1n ng\u01b0\u1ee3c \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 09 Gi\u1edbi thi\u1ec7u v\u1ec1 T\u1ed1i \u01b0u h\u00f3a \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 10 C\u00e1c B\u1ed9 t\u1ed1i \u01b0u (Optimizers) \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 11 Dropout \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> 12 \u0110\u1ed1i t\u01b0\u1ee3ng M\u00f4 h\u00ecnh (Model Object) \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> ... C\u00e1c nhi\u1ec7m v\u1ee5 n\u00e2ng cao... \u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u <code>[\u0110ang c\u1eadp nh\u1eadt]</code> <p>Ch\u00fa th\u00edch:</p> <ul> <li>\ud83d\udfe2 Ho\u00e0n th\u00e0nh (System Online): Module \u0111\u00e3 \u0111\u01b0\u1ee3c gi\u1ea3i m\u00e3 v\u00e0 th\u1ef1c thi.</li> <li>\ud83d\udfe1 \u0110ang ti\u1ebfn h\u00e0nh (Compiling...): \u0110ang trong qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng.</li> <li>\u26ab\ufe0f Ch\u01b0a b\u1eaft \u0111\u1ea7u (Awaiting Directive): Nhi\u1ec7m v\u1ee5 \u0111ang ch\u1edd \u0111\u01b0\u1ee3c k\u00edch ho\u1ea1t.</li> </ul>"},{"location":"#giao-thuc-khoi-chay-activation-protocol","title":"\u2699\ufe0f GIAO TH\u1ee8C KH\u1edeI CH\u1ea0Y (ACTIVATION PROTOCOL)","text":"<p>\u0110\u1ec3 t\u00e1i t\u1ea1o l\u1ea1i c\u00e1c th\u00ed nghi\u1ec7m trong kho l\u01b0u tr\u1eef n\u00e0y tr\u00ean h\u1ec7 th\u1ed1ng c\u1ee7a b\u1ea1n, h\u00e3y l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau:</p> <ol> <li> <p>Sao ch\u00e9p kho l\u01b0u tr\u1eef: Bash<pre><code>git clone https://github.com/dohuyhoang93/learn-nnfs.git\ncd learn-nnfs\n</code></pre></p> </li> <li> <p>Thi\u1ebft l\u1eadp m\u00f4i tr\u01b0\u1eddng \u1ea3o (khuy\u1ebfn ngh\u1ecb): Bash<pre><code>python -m venv venv\nsource venv/bin/activate  # Tr\u00ean Windows: venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>C\u00e0i \u0111\u1eb7t c\u00e1c g\u00f3i ph\u1ee5 thu\u1ed9c: Bash<pre><code>pip install numpy matplotlib\n</code></pre></p> </li> <li> <p>Th\u1ef1c thi m\u1ed9t module: Bash<pre><code>cd Chapter_XX_Ten_chuong\npython practice.py\n</code></pre></p> </li> </ol>"},{"location":"#tam-nhin-kien-truc-su-the-architects-vision","title":"\ud83d\udc41\ufe0f T\u1ea6M NH\u00ccN KI\u1ebeN TR\u00daC S\u01af (THE ARCHITECT'S VISION)","text":"<p>D\u1ef1 \u00e1n n\u00e0y v\u01b0\u1ee3t ra ngo\u00e0i m\u1ee5c ti\u00eau h\u1ecdc m\u1ed9t k\u1ef9 n\u0103ng m\u1edbi. \u0110\u00e2y l\u00e0 m\u1ed9t tuy\u00ean ng\u00f4n v\u1ec1 s\u1ef1 t\u00f2 m\u00f2, m\u1ed9t n\u1ed7 l\u1ef1c \u0111\u1ec3 hi\u1ec3u r\u00f5 n\u1ec1n t\u1ea3ng c\u1ee7a Tr\u00ed Tu\u1ec7 Nh\u00e2n T\u1ea1o. B\u1eb1ng c\u00e1ch x\u00e2y d\u1ef1ng m\u1ecdi th\u1ee9 t\u1eeb con s\u1ed1 kh\u00f4ng, ch\u00fang ta kh\u00f4ng ch\u1ec9 h\u1ecdc \"c\u00e1ch l\u00e0m\", m\u00e0 c\u00f2n th\u1ef1c s\u1ef1 th\u1ea5u hi\u1ec3u \"t\u1ea1i sao\".</p> <p>M\u1ed7i d\u00f2ng code l\u00e0 m\u1ed9t vi\u00ean g\u1ea1ch, m\u1ed7i h\u00e0m l\u00e0 m\u1ed9t m\u1ea1ch th\u1ea7n kinh, v\u00e0 to\u00e0n b\u1ed9 d\u1ef1 \u00e1n n\u00e0y l\u00e0 n\u1ed7 l\u1ef1c \u0111\u1ec3 x\u00e2y n\u00ean m\u1ed9t \"b\u1ed9 n\u00e3o\" t\u1eeb nh\u1eefng nguy\u00ean l\u00fd c\u01a1 b\u1ea3n nh\u1ea5t. Hy v\u1ecdng r\u1eb1ng h\u00e0nh tr\u00ecnh n\u00e0y s\u1ebd truy\u1ec1n c\u1ea3m h\u1ee9ng cho nh\u1eefng ai mu\u1ed1n kh\u00e1m ph\u00e1 v\u1ebb \u0111\u1eb9p thu\u1ea7n khi\u1ebft \u0111\u1eb1ng sau ma tr\u1eadn c\u1ee7a AI.</p> <p>H\u00e3y c\u00f9ng nhau ki\u1ebfn t\u1ea1o t\u01b0\u01a1ng lai.</p> <p>[Transmission Ends]</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/","title":"Ch4pt3r.01 - First Layer","text":""},{"location":"Explain%20Documents/01-first%20layer_explain/#giai-thich-chi-tiet-cho-oan-ma","title":"Gi\u1ea3i th\u00edch chi ti\u1ebft cho \u0111o\u1ea1n m\u00e3.","text":"<p>Ch\u01b0\u01a1ng tr\u00ecnh <code>fully_connect.py</code></p> <p>T\u1ed5ng quan: M\u1ee5c ti\u00eau c\u1ee7a ch\u01b0\u01a1ng tr\u00ecnh l\u00e0 g\u00ec?</p> <p>H\u00e3y t\u01b0\u1edfng t\u01b0\u1ee3ng ch\u00fang ta mu\u1ed1n x\u00e2y d\u1ef1ng m\u1ed9t \"b\u1ed9 n\u00e3o\" nh\u00e2n t\u1ea1o \u0111\u01a1n gi\u1ea3n. Ch\u01b0\u01a1ng tr\u00ecnh n\u00e0y th\u1ef1c hi\u1ec7n b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean v\u00e0 c\u01a1 b\u1ea3n nh\u1ea5t:</p> <ol> <li>X\u00e2y d\u1ef1ng m\u1ed9t \"n\u01a1-ron th\u1ea7n kinh\": T\u1ea1o ra m\u1ed9t \u0111\u01a1n v\u1ecb x\u1eed l\u00fd th\u00f4ng tin c\u01a1 b\u1ea3n.</li> <li>Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u: T\u1ea1o ra m\u1ed9t b\u1ed9 d\u1eef li\u1ec7u m\u1eabu \u0111\u1ec3 \"b\u1ed9 n\u00e3o\" c\u00f3 c\u00e1i \u0111\u1ec3 x\u1eed l\u00fd.</li> <li>Th\u1ef1c hi\u1ec7n m\u1ed9t ph\u00e9p t\u00ednh: \u0110\u01b0a d\u1eef li\u1ec7u qua \"b\u1ed9 n\u00e3o\" v\u00e0 xem k\u1ebft qu\u1ea3 \u0111\u1ea7u ra l\u00e0 g\u00ec.</li> </ol> <p>\u0110\u00e2y l\u00e0 n\u1ec1n t\u1ea3ng c\u1ee7a m\u1ecdi m\u1ea1ng n\u01a1-ron. Hi\u1ec3u r\u00f5 t\u1eebng d\u00f2ng m\u00e3 \u1edf \u0111\u00e2y s\u1ebd gi\u00fap b\u1ea1n n\u1eafm v\u1eefng c\u00e1c kh\u00e1i ni\u1ec7m ph\u1ee9c t\u1ea1p h\u01a1n sau n\u00e0y.</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#phan-1-chuan-bi-cong-cu-va-nguyen-lieu-imports-data","title":"Ph\u1ea7n 1: Chu\u1ea9n b\u1ecb c\u00f4ng c\u1ee5 v\u00e0 nguy\u00ean li\u1ec7u (Imports &amp; Data)","text":"<p>\u0110\u00e2y l\u00e0 b\u01b0\u1edbc ch\u00fang ta t\u1eadp h\u1ee3p c\u00e1c th\u01b0 vi\u1ec7n v\u00e0 d\u1eef li\u1ec7u c\u1ea7n thi\u1ebft tr\u01b0\u1edbc khi b\u1eaft \u0111\u1ea7u \"x\u00e2y d\u1ef1ng\".</p> Python<pre><code>import numpy as np\nimport nnfs\nimport matplotlib.pyplot as plt\n\nfrom nnfs.datasets import spiral_data\nnnfs.init()\n</code></pre>"},{"location":"Explain%20Documents/01-first%20layer_explain/#giai-thich-chi-tiet-tung-dong","title":"Gi\u1ea3i th\u00edch chi ti\u1ebft t\u1eebng d\u00f2ng:","text":"<ul> <li> <p><code>import numpy as np</code>:</p> <ul> <li>N\u00f3 l\u00e0 g\u00ec?: <code>NumPy</code> (Numerical Python) l\u00e0 th\u01b0 vi\u1ec7n c\u01a1 b\u1ea3n v\u00e0 quan tr\u1ecdng nh\u1ea5t cho khoa h\u1ecdc d\u1eef li\u1ec7u trong Python. N\u00f3 cung c\u1ea5p m\u1ed9t c\u1ea5u tr\u00fac d\u1eef li\u1ec7u c\u1ef1c k\u1ef3 hi\u1ec7u qu\u1ea3 g\u1ecdi l\u00e0 m\u1ea3ng (array) v\u00e0 c\u00e1c c\u00f4ng c\u1ee5 \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c ph\u00e9p to\u00e1n tr\u00ean m\u1ea3ng \u0111\u00f3, \u0111\u1eb7c bi\u1ec7t l\u00e0 to\u00e1n ma tr\u1eadn.</li> <li>T\u1ea1i sao c\u1ea7n n\u00f3?: M\u1ea1ng n\u01a1-ron v\u1ec1 b\u1ea3n ch\u1ea5t l\u00e0 m\u1ed9t chu\u1ed7i c\u00e1c ph\u00e9p to\u00e1n ma tr\u1eadn. NumPy gi\u00fap ch\u00fang ta th\u1ef1c hi\u1ec7n c\u00e1c ph\u00e9p nh\u00e2n, c\u1ed9ng ma tr\u1eadn n\u00e0y m\u1ed9t c\u00e1ch nhanh ch\u00f3ng v\u00e0 hi\u1ec7u qu\u1ea3 h\u01a1n r\u1ea5t nhi\u1ec1u so v\u1edbi vi\u1ec7c d\u00f9ng list th\u00f4ng th\u01b0\u1eddng c\u1ee7a Python. <code>as np</code> l\u00e0 m\u1ed9t quy \u01b0\u1edbc ph\u1ed5 bi\u1ebfn \u0111\u1ec3 \u0111\u1eb7t t\u00ean vi\u1ebft t\u1eaft cho th\u01b0 vi\u1ec7n.</li> </ul> </li> <li> <p><code>import nnfs</code>:</p> <ul> <li>N\u00f3 l\u00e0 g\u00ec?: <code>nnfs</code> (Neural Networks from Scratch) l\u00e0 m\u1ed9t th\u01b0 vi\u1ec7n h\u1ed7 tr\u1ee3 \u0111\u01b0\u1ee3c vi\u1ebft ri\u00eang cho cu\u1ed1n s\u00e1ch c\u00f9ng t\u00ean. M\u1ee5c \u0111\u00edch c\u1ee7a n\u00f3 l\u00e0 gi\u00fap ng\u01b0\u1eddi h\u1ecdc t\u1eadp trung v\u00e0o kh\u00e1i ni\u1ec7m m\u1ea1ng n\u01a1-ron thay v\u00ec b\u1ecb sa \u0111\u00e0 v\u00e0o c\u00e1c chi ti\u1ebft ph\u1ee5.</li> <li>T\u1ea1i sao c\u1ea7n n\u00f3?: N\u00f3 cung c\u1ea5p c\u00e1c h\u00e0m ti\u1ec7n \u00edch, nh\u01b0 t\u1ea1o d\u1eef li\u1ec7u m\u1eabu (<code>spiral_data</code>) v\u00e0 kh\u1edfi t\u1ea1o m\u00f4i tr\u01b0\u1eddng (<code>init</code>) \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o k\u1ebft qu\u1ea3 c\u1ee7a m\u1ecdi ng\u01b0\u1eddi \u0111\u1ec1u gi\u1ed1ng nhau, d\u1ec5 d\u00e0ng cho vi\u1ec7c h\u1ecdc v\u00e0 g\u1ee1 l\u1ed7i.</li> </ul> </li> <li> <p><code>import matplotlib.pyplot as plt</code>:</p> <ul> <li>N\u00f3 l\u00e0 g\u00ec?: <code>Matplotlib</code> l\u00e0 th\u01b0 vi\u1ec7n tr\u1ef1c quan h\u00f3a d\u1eef li\u1ec7u (v\u1ebd \u0111\u1ed3 th\u1ecb) ph\u1ed5 bi\u1ebfn nh\u1ea5t trong Python. <code>pyplot</code> l\u00e0 m\u1ed9t module trong Matplotlib cung c\u1ea5p giao di\u1ec7n gi\u1ed1ng nh\u01b0 MATLAB.</li> <li>T\u1ea1i sao c\u1ea7n n\u00f3?: \"Tr\u0103m nghe kh\u00f4ng b\u1eb1ng m\u1ed9t th\u1ea5y\". Th\u01b0 vi\u1ec7n n\u00e0y cho ph\u00e9p ch\u00fang ta v\u1ebd d\u1eef li\u1ec7u l\u00ean bi\u1ec3u \u0111\u1ed3 \u0111\u1ec3 xem n\u00f3 tr\u00f4ng nh\u01b0 th\u1ebf n\u00e0o. Vi\u1ec7c nh\u00ecn th\u1ea5y d\u1eef li\u1ec7u h\u00ecnh xo\u1eafn \u1ed1c gi\u00fap ta hi\u1ec3u r\u00f5 h\u01a1n b\u00e0i to\u00e1n m\u00e0 m\u1ea1ng n\u01a1-ron \u0111ang c\u1ed1 g\u1eafng gi\u1ea3i quy\u1ebft.</li> </ul> </li> <li> <p><code>from nnfs.datasets import spiral_data</code>:</p> <ul> <li>N\u00f3 l\u00e0 g\u00ec?: \u0110\u00e2y l\u00e0 m\u1ed9t l\u1ec7nh <code>import</code> c\u1ee5 th\u1ec3. Thay v\u00ec nh\u1eadp c\u1ea3 th\u01b0 vi\u1ec7n <code>nnfs.datasets</code>, ch\u00fang ta ch\u1ec9 l\u1ea5y ri\u00eang h\u00e0m <code>spiral_data</code> t\u1eeb \u0111\u00f3.</li> <li>T\u1ea1i sao c\u1ea7n n\u00f3?: <code>spiral_data</code> l\u00e0 m\u1ed9t h\u00e0m gi\u00fap t\u1ea1o ra b\u1ed9 d\u1eef li\u1ec7u h\u00ecnh xo\u1eafn \u1ed1c n\u1ed5i ti\u1ebfng, m\u1ed9t b\u00e0i to\u00e1n kinh \u0111i\u1ec3n \u0111\u1ec3 ki\u1ec3m tra kh\u1ea3 n\u0103ng c\u1ee7a c\u00e1c m\u00f4 h\u00ecnh ph\u00e2n lo\u1ea1i.</li> </ul> </li> <li> <p><code>nnfs.init()</code>:</p> <ul> <li>N\u00f3 l\u00e0 g\u00ec?: L\u1ec7nh n\u00e0y g\u1ecdi h\u00e0m <code>init</code> t\u1eeb th\u01b0 vi\u1ec7n <code>nnfs</code>.</li> <li>T\u1ea1i sao c\u1ea7n n\u00f3?: H\u00e0m n\u00e0y th\u1ef1c hi\u1ec7n m\u1ed9t s\u1ed1 c\u00e0i \u0111\u1eb7t n\u1ec1n, quan tr\u1ecdng nh\u1ea5t l\u00e0 c\u1ed1 \u0111\u1ecbnh seed cho vi\u1ec7c sinh s\u1ed1 ng\u1eabu nhi\u00ean c\u1ee7a NumPy v\u00e0 thi\u1ebft l\u1eadp ki\u1ec3u d\u1eef li\u1ec7u m\u1eb7c \u0111\u1ecbnh. \u0110i\u1ec1u n\u00e0y \u0111\u1ea3m b\u1ea3o r\u1eb1ng m\u1ed7i khi b\u1ea1n ch\u1ea1y l\u1ea1i m\u00e3, c\u00e1c \"tr\u1ecdng s\u1ed1 ng\u1eabu nhi\u00ean\" v\u00e0 \"d\u1eef li\u1ec7u\" \u0111\u01b0\u1ee3c t\u1ea1o ra s\u1ebd lu\u00f4n gi\u1ed1ng h\u1ec7t nhau, gi\u00fap vi\u1ec7c h\u1ecdc v\u00e0 t\u00e1i t\u1ea1o k\u1ebft qu\u1ea3 tr\u1edf n\u00ean nh\u1ea5t qu\u00e1n.</li> </ul> </li> </ul>"},{"location":"Explain%20Documents/01-first%20layer_explain/#phan-2-xay-dung-ban-thiet-ke-cua-mot-vi-giam-khao-class-layer_dense","title":"Ph\u1ea7n 2: X\u00e2y d\u1ef1ng \"B\u1ea3n thi\u1ebft k\u1ebf c\u1ee7a m\u1ed9t V\u1ecb Gi\u00e1m kh\u1ea3o\" (<code>class Layer_Dense</code>)","text":"<p>\u0110\u00e2y l\u00e0 tr\u00e1i tim c\u1ee7a ch\u01b0\u01a1ng tr\u00ecnh. Ch\u00fang ta kh\u00f4ng x\u00e2y d\u1ef1ng m\u1ed9t n\u01a1-ron ri\u00eang l\u1ebb, m\u00e0 l\u00e0 m\u1ed9t \"b\u1ea3n thi\u1ebft k\u1ebf\" (<code>class</code>) \u0111\u1ec3 c\u00f3 th\u1ec3 t\u1ea1o ra c\u1ea3 m\u1ed9t l\u1edbp/m\u1ed9t ban gi\u00e1m kh\u1ea3o m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng.</p> Python<pre><code>class Layer_Dense:\n        def __init__(self, n_inputs, n_neurons):\n            self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n            self.biases = np.zeros((1, n_neurons))\n        def forward(self, inputs):\n            self.output = np.dot(inputs, self.weights) + self.biases\n</code></pre>"},{"location":"Explain%20Documents/01-first%20layer_explain/#giai-thich-chi-tiet-tung-phan","title":"Gi\u1ea3i th\u00edch chi ti\u1ebft t\u1eebng ph\u1ea7n:","text":"<ul> <li> <p><code>class Layer_Dense:</code>: Khai b\u00e1o m\u1ed9t \"b\u1ea3n thi\u1ebft k\u1ebf\" t\u00ean l\u00e0 <code>Layer_Dense</code>. M\u1ecdi th\u1ee9 b\u00ean trong n\u00f3 s\u1ebd \u0111\u1ecbnh ngh\u0129a c\u00e1c thu\u1ed9c t\u00ednh v\u00e0 h\u00e0nh vi c\u1ee7a m\u1ed9t l\u1edbp n\u01a1-ron d\u00e0y \u0111\u1eb7c.</p> </li> <li> <p><code>def __init__(self, n_inputs, n_neurons):</code>: H\u00e0m kh\u1edfi t\u1ea1o (constructor).</p> <ul> <li>N\u00f3 l\u00e0m g\u00ec?: H\u00e0m n\u00e0y \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng g\u1ecdi m\u1ed7i khi m\u1ed9t \u0111\u1ed1i t\u01b0\u1ee3ng m\u1edbi \u0111\u01b0\u1ee3c t\u1ea1o ra t\u1eeb b\u1ea3n thi\u1ebft k\u1ebf n\u00e0y (v\u00ed d\u1ee5 <code>dense1 = Layer_Dense(...)</code>). N\u00f3 d\u00f9ng \u0111\u1ec3 thi\u1ebft l\u1eadp c\u00e1c thu\u1ed9c t\u00ednh ban \u0111\u1ea7u.</li> <li><code>self</code>: \u0110\u1ea1i di\u1ec7n cho ch\u00ednh \u0111\u1ed1i t\u01b0\u1ee3ng s\u1ebd \u0111\u01b0\u1ee3c t\u1ea1o ra. Khi b\u1ea1n g\u1ecdi <code>dense1.weights</code>, <code>self</code> ch\u00ednh l\u00e0 <code>dense1</code>.</li> <li><code>n_inputs</code>: S\u1ed1 l\u01b0\u1ee3ng \u0111\u1eb7c tr\u01b0ng \u0111\u1ea7u v\u00e0o m\u00e0 l\u1edbp n\u00e0y s\u1ebd nh\u1eadn (v\u00ed d\u1ee5: 2 \u0111\u1eb7c tr\u01b0ng l\u00e0 \"\u0110\u1ed9 \u0111\u1ecf\" v\u00e0 \"\u0110\u1ed9 tr\u00f2n\" c\u1ee7a hoa qu\u1ea3).</li> <li><code>n_neurons</code>: S\u1ed1 l\u01b0\u1ee3ng n\u01a1-ron trong l\u1edbp n\u00e0y (v\u00ed d\u1ee5: 3 gi\u00e1m kh\u1ea3o, m\u1ed7i ng\u01b0\u1eddi cho m\u1ed9t lo\u1ea1i qu\u1ea3).</li> <li><code>self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)</code>: \u0110\u00e2y l\u00e0 d\u00f2ng c\u1ef1c k\u1ef3 quan tr\u1ecdng.<ul> <li><code>np.random.randn(n_inputs, n_neurons)</code>: T\u1ea1o m\u1ed9t ma tr\u1eadn c\u00f3 k\u00edch th\u01b0\u1edbc <code>(s\u1ed1_\u0111\u1ea7u_v\u00e0o, s\u1ed1_n\u01a1_ron)</code> ch\u1ee9a \u0111\u1ea7y c\u00e1c s\u1ed1 ng\u1eabu nhi\u00ean theo ph\u00e2n ph\u1ed1i chu\u1ea9n (ph\u00e2n ph\u1ed1i Gauss, c\u00f3 gi\u00e1 tr\u1ecb trung b\u00ecnh l\u00e0 0 v\u00e0 ph\u01b0\u01a1ng sai l\u00e0 1). \u0110\u00e2y ch\u00ednh l\u00e0 \"s\u1ef1 \u01b0u ti\u00ean\" ban \u0111\u1ea7u, ho\u00e0n to\u00e0n ng\u1eabu nhi\u00ean c\u1ee7a c\u00e1c v\u1ecb gi\u00e1m kh\u1ea3o.</li> <li><code>* 0.01</code>: Nh\u00e2n t\u1ea5t c\u1ea3 c\u00e1c tr\u1ecdng s\u1ed1 ng\u1eabu nhi\u00ean v\u1edbi m\u1ed9t s\u1ed1 r\u1ea5t nh\u1ecf. \u0110\u00e2y l\u00e0 m\u1ed9t k\u1ef9 thu\u1eadt ph\u1ed5 bi\u1ebfn \u0111\u1ec3 ng\u0103n c\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u ra ban \u0111\u1ea7u qu\u00e1 l\u1edbn, gi\u00fap qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n sau n\u00e0y \u1ed5n \u0111\u1ecbnh h\u01a1n.</li> </ul> </li> <li><code>self.biases = np.zeros((1, n_neurons))</code>:<ul> <li><code>np.zeros((1, n_neurons))</code>: T\u1ea1o m\u1ed9t ma tr\u1eadn h\u00e0ng (vector) c\u00f3 k\u00edch th\u01b0\u1edbc <code>(1, s\u1ed1_n\u01a1_ron)</code> ch\u1ee9a to\u00e0n s\u1ed1 0. \u0110\u00e2y l\u00e0 \"th\u00e0nh ki\u1ebfn\" hay \"t\u00e2m tr\u1ea1ng\" ban \u0111\u1ea7u c\u1ee7a c\u00e1c v\u1ecb gi\u00e1m kh\u1ea3o. Vi\u1ec7c kh\u1edfi t\u1ea1o b\u1eb1ng 0 c\u00f3 ngh\u0129a l\u00e0 ban \u0111\u1ea7u, h\u1ecd kh\u00f4ng c\u00f3 b\u1ea5t k\u1ef3 thi\u00ean v\u1ecb n\u00e0o.</li> </ul> </li> </ul> </li> <li> <p><code>def forward(self, inputs):</code>: Ph\u01b0\u01a1ng th\u1ee9c h\u00e0nh \u0111\u1ed9ng.</p> <ul> <li>N\u00f3 l\u00e0m g\u00ec?: \u0110\u1ecbnh ngh\u0129a h\u00e0nh vi ch\u00ednh c\u1ee7a l\u1edbp: nh\u1eadn d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o v\u00e0 t\u00ednh to\u00e1n \u0111\u1ea7u ra. Qu\u00e1 tr\u00ecnh n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 truy\u1ec1n xu\u00f4i (forward pass).</li> <li><code>inputs</code>: D\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o s\u1ebd \u0111\u01b0\u1ee3c \u0111\u01b0a v\u00e0o l\u1edbp (v\u00ed d\u1ee5: danh s\u00e1ch c\u00e1c \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a t\u1ea5t c\u1ea3 hoa qu\u1ea3).</li> <li><code>self.output = np.dot(inputs, self.weights) + self.biases</code>: C\u00f4ng th\u1ee9c to\u00e1n h\u1ecdc c\u1ed1t l\u00f5i.<ul> <li><code>np.dot(inputs, self.weights)</code>: Ph\u00e9p nh\u00e2n ma tr\u1eadn. \u0110\u00e2y l\u00e0 l\u00fac m\u1ed7i gi\u00e1m kh\u1ea3o \"nh\u00ecn\" v\u00e0o c\u00e1c \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a hoa qu\u1ea3 v\u00e0 nh\u00e2n ch\u00fang v\u1edbi \"s\u1ef1 \u01b0u ti\u00ean\" (tr\u1ecdng s\u1ed1) c\u1ee7a m\u00ecnh \u0111\u1ec3 \u0111\u01b0a ra m\u1ed9t \u0111i\u1ec3m s\u1ed1 s\u01a1 b\u1ed9.</li> <li><code>+ self.biases</code>: C\u1ed9ng th\u00eam \"th\u00e0nh ki\u1ebfn\" (thi\u00ean v\u1ecb) c\u1ee7a m\u1ed7i gi\u00e1m kh\u1ea3o v\u00e0o \u0111i\u1ec3m s\u1ed1 c\u1ee7a h\u1ecd.</li> <li><code>self.output = ...</code>: K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o thu\u1ed9c t\u00ednh <code>output</code> c\u1ee7a l\u1edbp.</li> </ul> </li> </ul> </li> </ul>"},{"location":"Explain%20Documents/01-first%20layer_explain/#phan-3-cuoc-thi-bat-au-su-dung-lop-va-du-lieu","title":"Ph\u1ea7n 3: Cu\u1ed9c thi b\u1eaft \u0111\u1ea7u! (S\u1eed d\u1ee5ng l\u1edbp v\u00e0 d\u1eef li\u1ec7u)","text":"<p>B\u00e2y gi\u1edd ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng \"b\u1ea3n thi\u1ebft k\u1ebf\" v\u00e0 \"nguy\u00ean li\u1ec7u\" \u0111\u00e3 chu\u1ea9n b\u1ecb \u1edf tr\u00ean \u0111\u1ec3 ti\u1ebfn h\u00e0nh m\u1ed9t cu\u1ed9c thi th\u1ef1c s\u1ef1.</p> Python<pre><code># Create dataset\nX, y = spiral_data(samples=100, classes=3)\n# Visualize dataset\nplt.scatter(X[:,0], X[:,1], c=y, cmap='brg')\nplt.show()\n</code></pre> <ul> <li><code>X, y = spiral_data(samples=100, classes=3)</code>: G\u1ecdi h\u00e0m \u0111\u00e3 nh\u1eadp \u0111\u1ec3 t\u1ea1o d\u1eef li\u1ec7u.<ul> <li><code>X</code>: S\u1ebd l\u00e0 m\u1ed9t m\u1ea3ng NumPy k\u00edch th\u01b0\u1edbc <code>(300, 2)</code>. 300 l\u00e0 v\u00ec c\u00f3 3 l\u1edbp (<code>classes</code>), m\u1ed7i l\u1edbp 100 m\u1eabu (<code>samples</code>). 2 l\u00e0 v\u00ec m\u1ed7i m\u1eabu c\u00f3 2 \u0111\u1eb7c tr\u01b0ng (t\u1ecda \u0111\u1ed9 x, y). \u0110\u00e2y l\u00e0 \"danh s\u00e1ch c\u00e1c th\u00ed sinh hoa qu\u1ea3 v\u00e0 \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a ch\u00fang\".</li> <li><code>y</code>: S\u1ebd l\u00e0 m\u1ed9t m\u1ea3ng NumPy k\u00edch th\u01b0\u1edbc <code>(300,)</code> ch\u1ee9a c\u00e1c nh\u00e3n <code>0, 1, 2</code>. \u0110\u00e2y l\u00e0 \"\u0111\u00e1p \u00e1n \u0111\u00fang\" cho m\u1ed7i th\u00ed sinh (T\u00e1o, Cam, hay Chu\u1ed1i).</li> </ul> </li> <li><code>plt.scatter(X[:,0], X[:,1], c=y, cmap='brg')</code>: Chu\u1ea9n b\u1ecb v\u1ebd \u0111\u1ed3 th\u1ecb.<ul> <li><code>X[:,0]</code>: L\u1ea5y t\u1ea5t c\u1ea3 c\u00e1c h\u00e0ng, c\u1ed9t \u0111\u1ea7u ti\u00ean (t\u1ea5t c\u1ea3 t\u1ecda \u0111\u1ed9 x).</li> <li><code>X[:,1]</code>: L\u1ea5y t\u1ea5t c\u1ea3 c\u00e1c h\u00e0ng, c\u1ed9t th\u1ee9 hai (t\u1ea5t c\u1ea3 t\u1ecda \u0111\u1ed9 y).</li> <li><code>c=y</code>: <code>c</code> l\u00e0 vi\u1ebft t\u1eaft c\u1ee7a color. L\u1ec7nh n\u00e0y b\u1ea3o Matplotlib h\u00e3y t\u00f4 m\u00e0u cho m\u1ed7i \u0111i\u1ec3m <code>(x, y)</code> d\u1ef1a tr\u00ean gi\u00e1 tr\u1ecb t\u01b0\u01a1ng \u1ee9ng trong m\u1ea3ng <code>y</code>. C\u00e1c \u0111i\u1ec3m c\u00f3 <code>y=0</code> s\u1ebd c\u00f9ng m\u00e0u, <code>y=1</code> c\u00f9ng m\u00e0u kh\u00e1c,...</li> <li><code>cmap='brg'</code>: Color map. Ch\u1ecdn b\u1ea3ng m\u00e0u Xanh-\u0110\u1ecf-L\u00e1 (Blue-Red-Green).</li> </ul> </li> <li><code>plt.show()</code>: Hi\u1ec3n th\u1ecb \u0111\u1ed3 th\u1ecb \u0111\u00e3 chu\u1ea9n b\u1ecb l\u00ean m\u00e0n h\u00ecnh.</li> </ul> Python<pre><code># Create Dense layer with 2 input features and 3 output values\ndense1 = Layer_Dense(2, 3)\n</code></pre> <ul> <li>\u0110\u00e2y l\u00e0 l\u00fac ch\u00fang ta t\u1ea1o ra m\u1ed9t \u0111\u1ed1i t\u01b0\u1ee3ng t\u1eeb b\u1ea3n thi\u1ebft k\u1ebf <code>Layer_Dense</code>. Ch\u00fang ta \u0111ang \"thu\u00ea m\u1ed9t ban gi\u00e1m kh\u1ea3o\".</li> <li><code>dense1 = ...</code>: T\u1ea1o m\u1ed9t ban gi\u00e1m kh\u1ea3o c\u1ee5 th\u1ec3 t\u00ean l\u00e0 <code>dense1</code>.</li> <li><code>Layer_Dense(2, 3)</code>: G\u1ecdi h\u00e0m <code>__init__</code>.<ul> <li><code>n_inputs=2</code>: V\u00ec m\u1ed7i \"th\u00ed sinh hoa qu\u1ea3\" (<code>X</code>) c\u00f3 2 \u0111\u1eb7c tr\u01b0ng (t\u1ecda \u0111\u1ed9 x, y).</li> <li><code>n_neurons=3</code>: V\u00ec ch\u00fang ta c\u1ea7n ph\u00e2n lo\u1ea1i th\u00e0nh 3 lo\u1ea1i qu\u1ea3 (3 l\u1edbp trong <code>y</code>). Ch\u00fang ta c\u1ea7n 3 gi\u00e1m kh\u1ea3o, m\u1ed7i ng\u01b0\u1eddi chuy\u00ean v\u1ec1 m\u1ed9t lo\u1ea1i.</li> </ul> </li> </ul> Python<pre><code># Let's see initial weights and biases\nprint(\"&gt;&gt;&gt; Initial weights and biases of the first layer:\")\nprint(dense1.weights)\nprint(dense1.biases)\n</code></pre> <ul> <li>In ra c\u00e1c thu\u1ed9c t\u00ednh <code>weights</code> v\u00e0 <code>biases</code> c\u1ee7a \u0111\u1ed1i t\u01b0\u1ee3ng <code>dense1</code> v\u1eeba t\u1ea1o. \u0110i\u1ec1u n\u00e0y cho ch\u00fang ta th\u1ea5y \"s\u1ef1 \u01b0u ti\u00ean\" v\u00e0 \"th\u00e0nh ki\u1ebfn\" ban \u0111\u1ea7u, ho\u00e0n to\u00e0n ng\u1eabu nhi\u00ean c\u1ee7a ban gi\u00e1m kh\u1ea3o tr\u01b0\u1edbc khi h\u1ecd ch\u1ea5m \u0111i\u1ec3m b\u1ea5t k\u1ef3 th\u00ed sinh n\u00e0o.</li> </ul> Python<pre><code># Perform a forward pass of our training data through this layer\ndense1.forward(X)\n</code></pre> <ul> <li>\u0110\u00e2y l\u00e0 kho\u1ea3nh kh\u1eafc h\u00e0nh \u0111\u1ed9ng. Ch\u00fang ta g\u1ecdi ph\u01b0\u01a1ng th\u1ee9c <code>forward</code> c\u1ee7a <code>dense1</code> v\u00e0 \u0111\u01b0a to\u00e0n b\u1ed9 \"danh s\u00e1ch th\u00ed sinh\" (<code>X</code>) v\u00e0o. Ph\u00e9p t\u00ednh <code>np.dot(X, dense1.weights) + dense1.biases</code> \u0111\u01b0\u1ee3c th\u1ef1c thi. Ban gi\u00e1m kh\u1ea3o b\u1eaft \u0111\u1ea7u ch\u1ea5m \u0111i\u1ec3m.</li> </ul> Python<pre><code># Let's see output of the first few samples:\nprint(\"&gt;&gt;&gt; Output of the first few samples:\")\nprint(dense1.output[:5])\n</code></pre> <ul> <li>Sau khi <code>forward()</code> ch\u1ea1y xong, k\u1ebft qu\u1ea3 \u0111\u01b0\u1ee3c l\u01b0u trong <code>dense1.output</code>.</li> <li><code>dense1.output[:5]</code>: Ch\u00fang ta in ra k\u1ebft qu\u1ea3 ch\u1ea5m \u0111i\u1ec3m cho 5 \"th\u00ed sinh hoa qu\u1ea3\" \u0111\u1ea7u ti\u00ean \u0111\u1ec3 xem th\u1eed. M\u1ed7i h\u00e0ng l\u00e0 m\u1ed9t th\u00ed sinh, m\u1ed7i c\u1ed9t l\u00e0 \u0111i\u1ec3m s\u1ed1 t\u1eeb m\u1ed9t gi\u00e1m kh\u1ea3o. C\u00e1c gi\u00e1 tr\u1ecb n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 logits.</li> </ul>"},{"location":"Explain%20Documents/01-first%20layer_explain/#phan-4-dien-giai-truu-tuong-cuoc-thi-phan-loai-hoa-qua","title":"Ph\u1ea7n 4: Di\u1ec5n gi\u1ea3i tr\u1eebu t\u01b0\u1ee3ng - Cu\u1ed9c thi ph\u00e2n lo\u1ea1i hoa qu\u1ea3","text":"<p>H\u00e3y k\u1ec3 l\u1ea1i to\u00e0n b\u1ed9 c\u00e2u chuy\u1ec7n m\u1ed9t c\u00e1ch li\u1ec1n m\u1ea1ch:</p> <ol> <li> <p>B\u1ed1i c\u1ea3nh: Ch\u00fang ta t\u1ed5 ch\u1ee9c m\u1ed9t cu\u1ed9c thi \u0111\u1ec3 ph\u00e2n lo\u1ea1i 3 lo\u1ea1i qu\u1ea3: T\u00e1o, Cam, v\u00e0 Chu\u1ed1i.</p> </li> <li> <p>C\u00e1c th\u00ed sinh (<code>X</code>, <code>y</code>): C\u00f3 300 qu\u1ea3 tham gia. V\u1edbi m\u1ed7i qu\u1ea3, ch\u00fang ta d\u00f9ng m\u00e1y \u0111o \u0111\u01b0\u1ee3c 2 \u0111\u1eb7c \u0111i\u1ec3m: \"\u0110\u1ed9 \u0111\u1ecf\" v\u00e0 \"\u0110\u1ed9 tr\u00f2n\" (\u0111\u00e2y l\u00e0 2 c\u1ed9t c\u1ee7a <code>X</code>). Ch\u00fang ta c\u0169ng bi\u1ebft tr\u01b0\u1edbc \u0111\u00e1p \u00e1n m\u1ed7i qu\u1ea3 l\u00e0 g\u00ec (\u0111\u00e2y l\u00e0 <code>y</code>).</p> </li> <li> <p>Thu\u00ea ban gi\u00e1m kh\u1ea3o (<code>dense1 = Layer_Dense(2, 3)</code>): Ch\u00fang ta thu\u00ea m\u1ed9t ban gi\u00e1m kh\u1ea3o g\u1ed3m 3 ng\u01b0\u1eddi:</p> <ul> <li>Gi\u00e1m kh\u1ea3o 1: Chuy\u00ean gia v\u1ec1 T\u00e1o.</li> <li>Gi\u00e1m kh\u1ea3o 2: Chuy\u00ean gia v\u1ec1 Cam.</li> <li>Gi\u00e1m kh\u1ea3o 3: Chuy\u00ean gia v\u1ec1 Chu\u1ed1i. H\u1ecd l\u00e0 nh\u1eefng ng\u01b0\u1eddi m\u1edbi v\u00e0o ngh\u1ec1, n\u00ean \"ki\u1ebfn th\u1ee9c\" c\u1ee7a h\u1ecd ban \u0111\u1ea7u l\u00e0 ng\u1eabu nhi\u00ean.</li> </ul> </li> <li> <p>Ki\u1ebfn th\u1ee9c c\u1ee7a gi\u00e1m kh\u1ea3o (<code>weights</code> v\u00e0 <code>biases</code>):</p> <ul> <li>S\u1ef1 \u01b0u ti\u00ean (<code>weights</code>): M\u1ed7i gi\u00e1m kh\u1ea3o c\u00f3 m\u1ed9t b\u1ed9 \"\u01b0u ti\u00ean\" ri\u00eang cho 2 \u0111\u1eb7c \u0111i\u1ec3m \"\u0110\u1ed9 \u0111\u1ecf\" v\u00e0 \"\u0110\u1ed9 tr\u00f2n\". V\u00ed d\u1ee5, chuy\u00ean gia T\u00e1o l\u00fd t\u01b0\u1edfng s\u1ebd c\u00f3 \u01b0u ti\u00ean cao cho \"\u0110\u1ed9 \u0111\u1ecf\" v\u00e0 \"\u0110\u1ed9 tr\u00f2n\". Chuy\u00ean gia Chu\u1ed1i s\u1ebd c\u00f3 \u01b0u ti\u00ean \u00e2m cho \"\u0110\u1ed9 tr\u00f2n\" (v\u00ec chu\u1ed1i d\u00e0i). Nh\u01b0ng v\u00ec h\u1ecd l\u00e0 ng\u01b0\u1eddi m\u1edbi, c\u00e1c \u01b0u ti\u00ean n\u00e0y \u0111\u01b0\u1ee3c g\u00e1n ng\u1eabu nhi\u00ean (v\u00ed d\u1ee5: chuy\u00ean gia T\u00e1o l\u1ea1i c\u00f3 th\u1ec3 th\u00edch qu\u1ea3 kh\u00f4ng \u0111\u1ecf, chuy\u00ean gia Chu\u1ed1i l\u1ea1i th\u00edch qu\u1ea3 tr\u00f2n).</li> <li>T\u00e2m tr\u1ea1ng (<code>biases</code>): Ban \u0111\u1ea7u, c\u1ea3 3 gi\u00e1m kh\u1ea3o \u0111\u1ec1u c\u00f3 t\u00e2m tr\u1ea1ng trung l\u1eadp (b\u1eb1ng 0).</li> </ul> </li> <li> <p>Qu\u00e1 tr\u00ecnh ch\u1ea5m \u0111i\u1ec3m (<code>dense1.forward(X)</code>):</p> <ul> <li>T\u1eebng qu\u1ea3 m\u1ed9t \u0111\u01b0\u1ee3c \u0111\u01b0a ra tr\u01b0\u1edbc ban gi\u00e1m kh\u1ea3o.</li> <li>M\u1ed7i gi\u00e1m kh\u1ea3o t\u00ednh \u0111i\u1ec3m c\u1ee7a m\u00ecnh theo c\u00f4ng th\u1ee9c:     <code>\u0110i\u1ec3m = (\u0110\u1ed9 \u0111\u1ecf * \u01afu ti\u00ean cho \u0111\u1ed9 \u0111\u1ecf) + (\u0110\u1ed9 tr\u00f2n * \u01afu ti\u00ean cho \u0111\u1ed9 tr\u00f2n) + T\u00e2m tr\u1ea1ng</code></li> <li>Qu\u00e1 tr\u00ecnh n\u00e0y di\u1ec5n ra cho t\u1ea5t c\u1ea3 300 qu\u1ea3.</li> </ul> </li> <li> <p>B\u1ea3ng \u0111i\u1ec3m (<code>dense1.output</code>):</p> <ul> <li>K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng l\u00e0 m\u1ed9t b\u1ea3ng \u0111i\u1ec3m l\u1edbn. M\u1ed7i h\u00e0ng l\u00e0 m\u1ed9t qu\u1ea3, m\u1ed7i c\u1ed9t l\u00e0 \u0111i\u1ec3m s\u1ed1 t\u1eeb m\u1ed9t gi\u00e1m kh\u1ea3o.</li> <li>V\u00ed d\u1ee5, d\u00f2ng \u0111\u1ea7u ti\u00ean c\u00f3 th\u1ec3 l\u00e0 <code>[0.0012, -0.0045, 0.0031]</code>. \u0110i\u1ec1u n\u00e0y c\u00f3 ngh\u0129a l\u00e0 v\u1edbi ki\u1ebfn th\u1ee9c ng\u1eabu nhi\u00ean hi\u1ec7n t\u1ea1i, Gi\u00e1m kh\u1ea3o T\u00e1o cho qu\u1ea3 n\u00e0y 0.0012 \u0111i\u1ec3m, Gi\u00e1m kh\u1ea3o Cam cho -0.0045 \u0111i\u1ec3m, v\u00e0 Gi\u00e1m kh\u1ea3o Chu\u1ed1i cho 0.0031 \u0111i\u1ec3m.</li> </ul> </li> </ol> <p>K\u1ebft lu\u1eadn quan tr\u1ecdng: V\u00ec \"ki\u1ebfn th\u1ee9c\" (weights) c\u1ee7a ban gi\u00e1m kh\u1ea3o l\u00e0 ng\u1eabu nhi\u00ean, n\u00ean \"b\u1ea3ng \u0111i\u1ec3m\" (output) n\u00e0y ho\u00e0n to\u00e0n v\u00f4 ngh\u0129a. Qu\u00e1 tr\u00ecnh \"hu\u1ea5n luy\u1ec7n\" (training), kh\u00f4ng c\u00f3 trong m\u00e3 n\u00e0y, ch\u00ednh l\u00e0 vi\u1ec7c cho ban gi\u00e1m kh\u1ea3o xem \u0111\u00e1p \u00e1n \u0111\u00fang (<code>y</code>), ch\u1ec9 ra l\u1ed7i sai c\u1ee7a h\u1ecd, v\u00e0 gi\u00fap h\u1ecd \u0111i\u1ec1u ch\u1ec9nh l\u1ea1i \"s\u1ef1 \u01b0u ti\u00ean\" (<code>weights</code>) v\u00e0 \"t\u00e2m tr\u1ea1ng\" (<code>biases</code>) qua h\u00e0ng ng\u00e0n l\u1ea7n l\u1eb7p, \u0111\u1ec3 cu\u1ed1i c\u00f9ng b\u1ea3ng \u0111i\u1ec3m c\u1ee7a h\u1ecd ph\u1ea3n \u00e1nh \u0111\u00fang lo\u1ea1i qu\u1ea3.</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#phan-5-so-o-minh-hoa-ascii","title":"Ph\u1ea7n 5: S\u01a1 \u0111\u1ed3 minh h\u1ecda (ASCII)","text":"<p>S\u01a1 \u0111\u1ed3 cho m\u1ed9t qu\u1ea3 duy nh\u1ea5t \u0111i qua ban gi\u00e1m kh\u1ea3o:  Text Only<pre><code>        \u0110\u1ea6U V\u00c0O (1 qu\u1ea3)\n        (2 \u0111\u1eb7c tr\u01b0ng)\n        +----------------------+\n        | \u0110\u1ed9 \u0111\u1ecf, \u0110\u1ed9 tr\u00f2n       |\n        +----------------------+\n               |\n               |                                 BAN GI\u00c1M KH\u1ea2O (dense1)\n               |                                 (3 Gi\u00e1m kh\u1ea3o/N\u01a1-ron)\n               |\n               |       \u01afu ti\u00ean (w11, w21)      +--------------------+   (\u0110i\u1ec3m t\u1eeb GK T\u00e1o)\n               +-----------------------------&gt;|  Gi\u00e1m kh\u1ea3o T\u00c1O   + b1|-----&gt; output_1\n               |                             +--------------------+\n               |\n               |       \u01afu ti\u00ean (w12, w22)      +--------------------+   (\u0110i\u1ec3m t\u1eeb GK Cam)\n               +-----------------------------&gt;|  Gi\u00e1m kh\u1ea3o CAM   + b2|-----&gt; output_2\n               |                             +--------------------+\n               |\n               |       \u01afu ti\u00ean (w13, w23)      +--------------------+   (\u0110i\u1ec3m t\u1eeb GK Chu\u1ed1i)\n               +-----------------------------&gt;|  Gi\u00e1m kh\u1ea3o CHU\u1ed0I + b3|-----&gt; output_3\n                                             +--------------------+\n\n\nC\u00f4ng th\u1ee9c t\u00ednh \u0111i\u1ec3m c\u1ee7a Gi\u00e1m kh\u1ea3o T\u00c1O:\noutput_1 = (\u0110\u1ed9 \u0111\u1ecf * w11) + (\u0110\u1ed9 tr\u00f2n * w21) + b1\n\nK\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng cho 1 qu\u1ea3 l\u00e0 m\u1ed9t b\u1ed9 3 \u0111i\u1ec3m: [output_1, output_2, output_3]\n</code></pre></p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#phu-luc-giai-thich-spiral-data","title":"Ph\u1ee5 L\u1ee5c Gi\u1ea3i Th\u00edch - Spiral Data :","text":"<p>\u0110\u00e2y l\u00e0 ph\u1ea7n gi\u1ea3i th\u00edch v\u1ec1 \"D\u1eef li\u1ec7u h\u00ecnh xo\u1eafn \u1ed1c\" - nghe c\u00f3 v\u1ebb tr\u1eebu t\u01b0\u1ee3ng, nh\u01b0ng n\u00f3 l\u00e0 m\u1ed9t trong nh\u1eefng b\u1ed9 d\u1eef li\u1ec7u m\u1eabu kinh \u0111i\u1ec3n v\u00e0 quan tr\u1ecdng nh\u1ea5t khi b\u1eaft \u0111\u1ea7u h\u1ecdc v\u1ec1 m\u1ea1ng n\u01a1-ron.</p> <p>H\u00e3y c\u00f9ng ph\u00e2n t\u00edch.</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#1-inh-nghia-on-gian","title":"1. \u0110\u1ecbnh ngh\u0129a \u0111\u01a1n gi\u1ea3n","text":"<p>D\u1eef li\u1ec7u h\u00ecnh xo\u1eafn \u1ed1c (Spiral Data) l\u00e0 m\u1ed9t b\u1ed9 d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c t\u1ea1o ra m\u1ed9t c\u00e1ch nh\u00e2n t\u1ea1o, trong \u0111\u00f3 c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u thu\u1ed9c c\u00e1c l\u1edbp kh\u00e1c nhau \u0111\u01b0\u1ee3c s\u1eafp x\u1ebfp th\u00e0nh c\u00e1c h\u00ecnh xo\u1eafn \u1ed1c l\u1ed3ng v\u00e0o nhau.</p> <p>H\u00e3y nh\u00ecn l\u1ea1i ch\u00ednh bi\u1ec3u \u0111\u1ed3 m\u00e0 b\u1ea1n \u0111\u00e3 t\u1ea1o ra:</p> <ul> <li>B\u1ea1n c\u00f3 3 l\u1edbp (classes), t\u01b0\u01a1ng \u1ee9ng v\u1edbi 3 m\u00e0u: \u0110\u1ecf, Xanh l\u00e1, v\u00e0 Xanh d\u01b0\u01a1ng.</li> <li>M\u1ed7i \u0111i\u1ec3m c\u00f3 m\u1ed9t v\u1ecb tr\u00ed (t\u1ecda \u0111\u1ed9 x, y).</li> <li>C\u00e1c \u0111i\u1ec3m c\u00f9ng m\u00e0u t\u1ea1o th\u00e0nh m\u1ed9t \"c\u00e1nh tay\" xo\u1eafn \u1ed1c.</li> <li>C\u00e1c c\u00e1nh tay n\u00e0y \u0111an xen, qu\u1ea5n l\u1ea5y nhau.</li> </ul>"},{"location":"Explain%20Documents/01-first%20layer_explain/#2-tai-sao-no-lai-quan-trong-va-noi-tieng","title":"2. T\u1ea1i sao n\u00f3 l\u1ea1i quan tr\u1ecdng v\u00e0 n\u1ed5i ti\u1ebfng?","text":"<p>L\u00fd do b\u1ed9 d\u1eef li\u1ec7u n\u00e0y \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng r\u1ed9ng r\u00e3i l\u00e0 v\u00ec n\u00f3 l\u00e0 m\u1ed9t th\u1eed th\u00e1ch ho\u00e0n h\u1ea3o \u0111\u1ec3 ch\u1ee9ng minh s\u1ee9c m\u1ea1nh c\u1ee7a m\u1ea1ng n\u01a1-ron.</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#a-no-anh-bai-cac-mo-hinh-on-gian-tuyen-tinh","title":"A. N\u00f3 \"\u0111\u00e1nh b\u1ea1i\" c\u00e1c m\u00f4 h\u00ecnh \u0111\u01a1n gi\u1ea3n (Tuy\u1ebfn t\u00ednh)","text":"<p>H\u00e3y t\u01b0\u1edfng t\u01b0\u1ee3ng b\u1ea1n ch\u1ec9 c\u00f3 m\u1ed9t c\u00e2y th\u01b0\u1edbc k\u1ebb. Nhi\u1ec7m v\u1ee5 c\u1ee7a b\u1ea1n l\u00e0 k\u1ebb m\u1ed9t ho\u1eb7c nhi\u1ec1u \u0111\u01b0\u1eddng th\u1eb3ng \u0111\u1ec3 ph\u00e2n chia 3 nh\u00f3m m\u00e0u n\u00e0y ra, sao cho m\u1ed7i v\u00f9ng ch\u1ec9 ch\u1ee9a m\u1ed9t m\u00e0u duy nh\u1ea5t.</p> <p>B\u1ea1n s\u1ebd th\u1ea5y ngay l\u00e0 b\u1ea5t kh\u1ea3 thi.</p> Text Only<pre><code>       /\n      /    &lt;-- B\u1ea1n kh\u00f4ng th\u1ec3 k\u1ebb m\u1ed9t \u0111\u01b0\u1eddng th\u1eb3ng n\u00e0o\n     /         \u0111\u1ec3 t\u00e1ch m\u00e0u \u0110\u1ecf (R) ra kh\u1ecfi Xanh (G) v\u00e0 Xanh d\u01b0\u01a1ng (B)\n    /\n   RRRRR\n  G B R G\n B G R B G\nB B G G B B\n R R B R R\n  R G B R\n   BBBBB\n</code></pre> <p>M\u1ed9t m\u00f4 h\u00ecnh ch\u1ec9 c\u00f3 th\u1ec3 k\u1ebb c\u00e1c \u0111\u01b0\u1eddng th\u1eb3ng \u0111\u1ec3 ph\u00e2n lo\u1ea1i \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 m\u00f4 h\u00ecnh tuy\u1ebfn t\u00ednh (linear model). D\u1eef li\u1ec7u xo\u1eafn \u1ed1c l\u00e0 m\u1ed9t v\u00ed d\u1ee5 kinh \u0111i\u1ec3n c\u1ee7a d\u1eef li\u1ec7u phi tuy\u1ebfn (non-linear), n\u01a1i ranh gi\u1edbi gi\u1eefa c\u00e1c l\u1edbp kh\u00f4ng ph\u1ea3i l\u00e0 \u0111\u01b0\u1eddng th\u1eb3ng m\u00e0 l\u00e0 nh\u1eefng \u0111\u01b0\u1eddng cong ph\u1ee9c t\u1ea1p.</p> <p>N\u00f3i c\u00e1ch kh\u00e1c, d\u1eef li\u1ec7u xo\u1eafn \u1ed1c \u0111\u01b0\u1ee3c t\u1ea1o ra \u0111\u1ec3 c\u1ed1 t\u00ecnh l\u00e0m kh\u00f3 c\u00e1c thu\u1eadt to\u00e1n ph\u00e2n lo\u1ea1i \u0111\u01a1n gi\u1ea3n.</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#b-no-chung-to-su-can-thiet-cua-mang-no-ron","title":"B. N\u00f3 ch\u1ee9ng t\u1ecf s\u1ef1 c\u1ea7n thi\u1ebft c\u1ee7a M\u1ea1ng N\u01a1-ron","text":"<p>M\u1ea1ng n\u01a1-ron, \u0111\u1eb7c bi\u1ec7t l\u00e0 c\u00e1c m\u1ea1ng c\u00f3 c\u00e1c l\u1edbp \u1ea9n (hidden layers) v\u00e0 c\u00e1c h\u00e0m k\u00edch ho\u1ea1t phi tuy\u1ebfn (s\u1ebd h\u1ecdc sau), c\u00f3 kh\u1ea3 n\u0103ng h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1c ranh gi\u1edbi quy\u1ebft \u0111\u1ecbnh (decision boundaries) c\u1ef1c k\u1ef3 ph\u1ee9c t\u1ea1p v\u00e0 u\u1ed1n l\u01b0\u1ee3n.</p> <p>M\u1ed9t m\u1ea1ng n\u01a1-ron \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n t\u1ed1t c\u00f3 th\u1ec3 t\u1ea1o ra m\u1ed9t ranh gi\u1edbi tr\u00f4ng gi\u1ed1ng nh\u01b0 th\u1ebf n\u00e0y:</p> <p>N\u00f3 kh\u00f4ng d\u00f9ng \"th\u01b0\u1edbc k\u1ebb\", m\u00e0 n\u00f3 h\u1ecdc c\u00e1ch \"v\u1ebd\" ra nh\u1eefng \u0111\u01b0\u1eddng cong m\u1ec1m m\u1ea1i \u0111\u1ec3 bao quanh t\u1eebng nh\u00f3m d\u1eef li\u1ec7u m\u1ed9t c\u00e1ch ho\u00e0n h\u1ea3o.</p> <p>K\u1ebft lu\u1eadn: D\u1eef li\u1ec7u xo\u1eafn \u1ed1c l\u00e0 m\u1ed9t b\u00e0i ki\u1ec3m tra \"t\u1ed1t nghi\u1ec7p\" cho m\u1ed9t m\u00f4 h\u00ecnh ph\u00e2n lo\u1ea1i. N\u1ebfu m\u00f4 h\u00ecnh c\u1ee7a b\u1ea1n c\u00f3 th\u1ec3 gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c b\u00e0i to\u00e1n n\u00e0y, n\u00f3 ch\u1ee9ng t\u1ecf r\u1eb1ng n\u00f3 c\u00f3 kh\u1ea3 n\u0103ng x\u1eed l\u00fd c\u00e1c m\u1ed1i quan h\u1ec7 ph\u1ee9c t\u1ea1p, phi tuy\u1ebfn trong d\u1eef li\u1ec7u, \u0111i\u1ec1u m\u00e0 c\u00e1c m\u00f4 h\u00ecnh \u0111\u01a1n gi\u1ea3n kh\u00f4ng l\u00e0m \u0111\u01b0\u1ee3c.</p>"},{"location":"Explain%20Documents/01-first%20layer_explain/#3-ham-spiral_data-tao-ra-cai-gi","title":"3. H\u00e0m <code>spiral_data</code> t\u1ea1o ra c\u00e1i g\u00ec?","text":"<p>Khi b\u1ea1n g\u1ecdi <code>X, y = spiral_data(samples=100, classes=3)</code>, h\u00e0m n\u00e0y s\u1ebd t\u00ednh to\u00e1n v\u00e0 tr\u1ea3 v\u1ec1 hai th\u1ee9:</p> <ol> <li> <p><code>X</code> (C\u00e1c \u0111\u1eb7c tr\u01b0ng - The Features):</p> <ul> <li>L\u00e0 m\u1ed9t m\u1ea3ng NumPy ch\u1ee9a t\u1ecda \u0111\u1ed9 <code>[x, y]</code> c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m.</li> <li>V\u1edbi <code>samples=100</code> v\u00e0 <code>classes=3</code>, n\u00f3 s\u1ebd t\u1ea1o ra <code>100 * 3 = 300</code> \u0111i\u1ec3m.</li> <li>V\u00ec v\u1eady, <code>X</code> s\u1ebd c\u00f3 k\u00edch th\u01b0\u1edbc l\u00e0 <code>(300, 2)</code>.</li> <li>Trong c\u00e2u chuy\u1ec7n \"gi\u00e1m kh\u1ea3o hoa qu\u1ea3\" c\u1ee7a ch\u00fang ta, <code>X</code> t\u01b0\u01a1ng \u0111\u01b0\u01a1ng v\u1edbi m\u1ed9t danh s\u00e1ch 300 qu\u1ea3, m\u1ed7i qu\u1ea3 c\u00f3 2 \u0111\u1eb7c \u0111i\u1ec3m l\u00e0 \"\u0110\u1ed9 \u0111\u1ecf\" v\u00e0 \"\u0110 \u0110\u1ed9 tr\u00f2n\".</li> </ul> </li> <li> <p><code>y</code> (C\u00e1c nh\u00e3n - The Labels):</p> <ul> <li>L\u00e0 m\u1ed9t m\u1ea3ng NumPy ch\u1ee9a nh\u00e3n l\u1edbp cho m\u1ed7i \u0111i\u1ec3m t\u01b0\u01a1ng \u1ee9ng trong <code>X</code>.</li> <li>N\u00f3 s\u1ebd ch\u1ee9a 300 con s\u1ed1, bao g\u1ed3m 100 s\u1ed1 <code>0</code>, 100 s\u1ed1 <code>1</code>, v\u00e0 100 s\u1ed1 <code>2</code>.</li> <li><code>y[i]</code> l\u00e0 nh\u00e3n (\u0111\u00e1p \u00e1n \u0111\u00fang) cho \u0111i\u1ec3m <code>X[i]</code>.</li> <li>Trong c\u00e2u chuy\u1ec7n c\u1ee7a ch\u00fang ta, <code>y</code> l\u00e0 danh s\u00e1ch \u0111\u00e1p \u00e1n \u0111\u00fang: qu\u1ea3 n\u00e0o l\u00e0 \"T\u00e1o\" (l\u1edbp 0), qu\u1ea3 n\u00e0o l\u00e0 \"Cam\" (l\u1edbp 1), qu\u1ea3 n\u00e0o l\u00e0 \"Chu\u1ed1i\" (l\u1edbp 2).</li> </ul> </li> </ol> <p>V\u00ec v\u1eady, <code>spiral_data</code> kh\u00f4ng ch\u1ec9 l\u00e0 m\u1ed9t b\u1ed9 d\u1eef li\u1ec7u, m\u00e0 n\u00f3 l\u00e0 m\u1ed9t b\u00e0i to\u00e1n ph\u00e2n lo\u1ea1i phi tuy\u1ebfn kinh \u0111i\u1ec3n \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i s\u1eb5n \u0111\u1ec3 b\u1ea1n c\u00f3 th\u1ec3 nhanh ch\u00f3ng ki\u1ec3m tra m\u00f4 h\u00ecnh c\u1ee7a m\u00ecnh.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/","title":"Ch4pt3r.02 - Transformation & ReLU activation function","text":""},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#phan-1-ham-kich-hoat-relu","title":"Ph\u1ea7n 1: H\u00e0m k\u00edch ho\u1ea1t ReLU","text":"<p>\u0110\u00e2y l\u00e0 m\u1ed9t trong nh\u1eefng ph\u1ea7n minh h\u1ecda hay nh\u1ea5t v\u1ec1 s\u1ee9c m\u1ea1nh c\u1ee7a h\u00e0m k\u00edch ho\u1ea1t ReLU, m\u1ed9t kh\u00e1i ni\u1ec7m n\u1ec1n t\u1ea3ng c\u1ee7a m\u1ea1ng neural hi\u1ec7n \u0111\u1ea1i.</p> <p>M\u1ee5c ti\u00eau ch\u00ednh c\u1ee7a ch\u01b0\u01a1ng n\u00e0y l\u00e0 tr\u1ea3 l\u1eddi c\u00e2u h\u1ecfi: \"L\u00e0m th\u1ebf n\u00e0o m\u1ed9t h\u00e0m \u0111\u01a1n gi\u1ea3n nh\u01b0 ReLU, v\u1ed1n ch\u1ec9 l\u00e0 m\u1ed9t \u0111\u01b0\u1eddng th\u1eb3ng b\u1ecb 'b\u1ebb g\u00e3y' t\u1ea1i \u0111i\u1ec3m 0, l\u1ea1i c\u00f3 th\u1ec3 gi\u00fap m\u1ea1ng neural h\u1ecdc \u0111\u01b0\u1ee3c c\u00e1c m\u1ed1i quan h\u1ec7 phi tuy\u1ebfn v\u00f4 c\u00f9ng ph\u1ee9c t\u1ea1p (nh\u01b0 h\u00ecnh sin)?\"</p> <p>H\u00e3y c\u00f9ng m\u1ed5 x\u1ebb n\u00f3 t\u1eebng b\u01b0\u1edbc m\u1ed9t.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#tom-tat-y-tuong-lon-the-big-idea","title":"T\u00f3m T\u1eaft \u00dd T\u01b0\u1edfng L\u1edbn (The Big Idea)","text":"<p>H\u00e3y t\u01b0\u1edfng t\u01b0\u1ee3ng b\u1ea1n ch\u1ec9 c\u00f3 c\u00e1c vi\u00ean g\u1ea1ch LEGO th\u1eb3ng. L\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 d\u00f9ng ch\u00fang x\u00e2y m\u1ed9t b\u1ee9c t\u01b0\u1eddng cong?</p> <p>C\u00e2u tr\u1ea3 l\u1eddi l\u00e0: B\u1ea1n kh\u00f4ng th\u1ec3 t\u1ea1o ra m\u1ed9t \u0111\u01b0\u1eddng cong m\u01b0\u1ee3t m\u00e0, nh\u01b0ng b\u1ea1n c\u00f3 th\u1ec3 x\u1ea5p x\u1ec9 (approximate) n\u00f3 b\u1eb1ng c\u00e1ch gh\u00e9p r\u1ea5t nhi\u1ec1u vi\u00ean g\u1ea1ch th\u1eb3ng ng\u1eafn l\u1ea1i v\u1edbi nhau. C\u00e0ng nhi\u1ec1u vi\u00ean g\u1ea1ch ng\u1eafn, b\u1ee9c t\u01b0\u1eddng c\u1ee7a b\u1ea1n tr\u00f4ng s\u1ebd c\u00e0ng cong v\u00e0 m\u01b0\u1ee3t.</p> <p>Trong m\u1ea1ng neural:</p> <ul> <li>H\u00e0m ReLU ch\u00ednh l\u00e0 vi\u00ean g\u1ea1ch th\u1eb3ng c\u1ee7a ch\u00fang ta.</li> <li>M\u1ed7i neuron (ho\u1eb7c c\u1eb7p neuron) l\u00e0 m\u1ed9t ng\u01b0\u1eddi th\u1ee3 x\u00e2y, c\u00f3 nhi\u1ec7m v\u1ee5 \u0111\u1eb7t m\u1ed9t vi\u00ean g\u1ea1ch.</li> <li>M\u1ea1ng neural l\u00e0 c\u1ea3 c\u00f4ng tr\u00ecnh, gh\u00e9p c\u00e1c vi\u00ean g\u1ea1ch n\u00e0y l\u1ea1i \u0111\u1ec3 t\u1ea1o ra h\u00ecnh d\u1ea1ng ph\u1ee9c t\u1ea1p cu\u1ed1i c\u00f9ng (nh\u01b0 \u0111\u01b0\u1eddng cong h\u00ecnh sin).</li> </ul> <p>Gi\u1edd h\u00e3y \u0111i v\u00e0o chi ti\u1ebft c\u00e1ch \"ng\u01b0\u1eddi th\u1ee3\" neuron l\u00e0m vi\u1ec7c.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#khoi-xay-dung-co-ban-mot-neuron-relu","title":"Kh\u1ed1i X\u00e2y D\u1ef1ng C\u01a1 B\u1ea3n - M\u1ed9t Neuron ReLU","text":"<p>M\u1ed9t neuron nh\u1eadn \u0111\u1ea7u v\u00e0o (input), nh\u00e2n v\u1edbi tr\u1ecdng s\u1ed1 (weight), c\u1ed9ng v\u1edbi thi\u00ean v\u1ecb (bias), r\u1ed3i cho qua h\u00e0m k\u00edch ho\u1ea1t ReLU.</p> <p>C\u00f4ng th\u1ee9c: <code>output = ReLU(weight * input + bias)</code> H\u00e0m ReLU: <code>ReLU(x) = max(0, x)</code>. Ngh\u0129a l\u00e0: *   N\u1ebfu <code>x &lt;= 0</code>, k\u1ebft qu\u1ea3 l\u00e0 <code>0</code>. *   N\u1ebfu <code>x &gt; 0</code>, k\u1ebft qu\u1ea3 l\u00e0 <code>x</code>.</p> <p>N\u00f3 gi\u1ed1ng nh\u01b0 m\u1ed9t c\u00e1i c\u1ed5ng: *   Input t\u00ednh to\u00e1n ra \u00e2m -&gt; C\u1ed5ng \u0111\u00f3ng -&gt; Output = 0. *   Input t\u00ednh to\u00e1n ra d\u01b0\u01a1ng -&gt; C\u1ed5ng m\u1edf -&gt; Output = gi\u00e1 tr\u1ecb t\u00ednh \u0111\u01b0\u1ee3c.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#vai-tro-cua-trong-so-weight-va-thien-vi-bias","title":"Vai tr\u00f2 c\u1ee7a Tr\u1ecdng s\u1ed1 (Weight) v\u00e0 Thi\u00ean v\u1ecb (Bias):","text":"<ol> <li> <p>Tr\u1ecdng s\u1ed1 (Weight): Thay \u0111\u1ed5i \u0111\u1ed9 d\u1ed1c.</p> <ul> <li>Weight l\u1edbn -&gt; \u0110\u01b0\u1eddng d\u1ed1c l\u00ean nhanh h\u01a1n.</li> <li>Weight nh\u1ecf -&gt; \u0110\u01b0\u1eddng d\u1ed1c l\u00ean tho\u1ea3i h\u01a1n.</li> <li>Weight \u00e2m -&gt; \u0110\u01b0\u1eddng b\u1ecb l\u1eadt ng\u01b0\u1ee3c, d\u1ed1c xu\u1ed1ng.</li> </ul> </li> <li> <p>Thi\u00ean v\u1ecb (Bias): D\u1ecbch chuy\u1ec3n \u0111i\u1ec3m \"b\u1ebb g\u00e3y\".</p> <ul> <li>Bias quy\u1ebft \u0111\u1ecbnh t\u1ea1i gi\u00e1 tr\u1ecb input n\u00e0o th\u00ec neuron b\u1eaft \u0111\u1ea7u \"k\u00edch ho\u1ea1t\" (t\u1ee9c l\u00e0 cho ra output &gt; 0). N\u00f3 d\u1ecbch chuy\u1ec3n \u0111\u1ed3 th\u1ecb sang tr\u00e1i ho\u1eb7c ph\u1ea3i.</li> </ul> </li> </ol> <p>Minh h\u1ecda ASCII:</p> <p>H\u00e3y xem \u0111\u1ed3 th\u1ecb c\u1ee7a m\u1ed9t neuron ReLU. Tr\u1ee5c ho\u00e0nh l\u00e0 <code>input</code>, tr\u1ee5c tung l\u00e0 <code>output</code>.</p> Text Only<pre><code>        C\u01a1 b\u1ea3n (w=1, b=0)          T\u0103ng Weight (w=2)           Th\u00eam Bias (w=1, b= -1)\n           /                          //                              /\n          /                          / /                             /\n         /                          / /                             /\n        +------- (input)          +------- (input)                +------- (input)\n                                                                 |\n                                                               (\u0111i\u1ec3m b\u1ebb g\u00e3y d\u1ecbch sang ph\u1ea3i)\n</code></pre> <p>T\u00f3m l\u1ea1i: V\u1edbi m\u1ed9t neuron, ch\u00fang ta c\u00f3 th\u1ec3 t\u1ea1o ra m\u1ed9t \"\u0111o\u1ea1n d\u1ed1c\" b\u1eaft \u0111\u1ea7u t\u1eeb m\u1ed9t \u0111i\u1ec3m t\u00f9y \u00fd v\u00e0 c\u00f3 \u0111\u1ed9 d\u1ed1c t\u00f9y \u00fd. Nh\u01b0ng n\u00f3 v\u1eabn ch\u1ec9 l\u00e0 m\u1ed9t \u0111\u01b0\u1eddng th\u1eb3ng.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#phep-mau-bat-au-ket-hop-hai-neuron","title":"Ph\u00e9p M\u00e0u B\u1eaft \u0110\u1ea7u - K\u1ebft H\u1ee3p Hai Neuron","text":"<p>\u0110\u00e2y l\u00e0 ph\u1ea7n c\u1ed1t l\u00f5i v\u00e0 k\u1ef3 di\u1ec7u nh\u1ea5t. S\u00e1ch minh h\u1ecda b\u1eb1ng c\u00e1ch d\u00f9ng m\u1ed9t c\u1eb7p neuron (m\u1ed9t \u1edf l\u1edbp \u1ea9n 1, m\u1ed9t \u1edf l\u1edbp \u1ea9n 2). Khi k\u1ebft h\u1ee3p ch\u00fang l\u1ea1i, ch\u00fang ta c\u00f3 th\u1ec3 t\u1ea1o ra m\u1ed9t th\u1ee9 g\u1ecdi l\u00e0 \"v\u00f9ng \u1ea3nh h\u01b0\u1edfng\" (area of effect).</p> <p>H\u00e3y t\u01b0\u1edfng t\u01b0\u1ee3ng th\u1ebf n\u00e0y:</p> <ol> <li> <p>Neuron 1 (Neuron \"K\u00edch ho\u1ea1t\"): T\u1ea1o ra m\u1ed9t \u0111\u01b0\u1eddng d\u1ed1c l\u00ean.</p> <ul> <li>V\u00ed d\u1ee5: <code>y1 = ReLU(1.0 * x - 0.2)</code></li> <li>N\u00f3 s\u1ebd t\u1ea1o ra m\u1ed9t \u0111\u01b0\u1eddng d\u1ed1c l\u00ean, b\u1eaft \u0111\u1ea7u t\u1eeb <code>x = 0.2</code>.</li> </ul> </li> <li> <p>Neuron 2 (Neuron \"V\u00f4 hi\u1ec7u h\u00f3a\"): T\u1ea1o ra m\u1ed9t \u0111\u01b0\u1eddng d\u1ed1c xu\u1ed1ng.</p> <ul> <li>V\u00ed d\u1ee5: <code>y2 = ReLU(-1.0 * x + 0.8)</code></li> <li>N\u00f3 s\u1ebd t\u1ea1o ra m\u1ed9t \u0111\u01b0\u1eddng d\u1ed1c xu\u1ed1ng, b\u1eaft \u0111\u1ea7u t\u1eeb <code>x = 0.8</code>.</li> </ul> </li> </ol> <p>Khi b\u1ea1n c\u1ed9ng k\u1ebft qu\u1ea3 c\u1ee7a hai neuron n\u00e0y l\u1ea1i (\u0111\u00e2y l\u00e0 \u0111i\u1ec1u x\u1ea3y ra \u1edf l\u1edbp ti\u1ebfp theo), \u0111i\u1ec1u th\u00fa v\u1ecb s\u1ebd x\u1ea3y ra:</p> <ul> <li>Khi x &lt; 0.2: C\u1ea3 hai neuron \u0111\u1ec1u cho output l\u00e0 0. T\u1ed5ng l\u00e0 0.</li> <li>Khi 0.2 &lt; x &lt; 0.8: Neuron 1 ho\u1ea1t \u0111\u1ed9ng (d\u1ed1c l\u00ean), Neuron 2 v\u1eabn l\u00e0 0. T\u1ed5ng l\u00e0 m\u1ed9t \u0111\u01b0\u1eddng d\u1ed1c l\u00ean.</li> <li>Khi x &gt; 0.8: C\u1ea3 hai neuron \u0111\u1ec1u ho\u1ea1t \u0111\u1ed9ng. \u0110\u01b0\u1eddng d\u1ed1c l\u00ean c\u1ee7a Neuron 1 s\u1ebd b\u1ecb tri\u1ec7t ti\u00eau b\u1edfi \u0111\u01b0\u1eddng d\u1ed1c xu\u1ed1ng c\u1ee7a Neuron 2. T\u1ed5ng l\u00e0 m\u1ed9t \u0111\u01b0\u1eddng n\u1eb1m ngang.</li> </ul> <p>K\u1ebft qu\u1ea3 l\u00e0 m\u1ed9t h\u00ecnh \"c\u00e1i l\u1ec1u\" ho\u1eb7c \"c\u00e1i n\u00f3n\"!</p> <p>Minh h\u1ecda ASCII:</p> Text Only<pre><code>   \u0110\u1ea7u ra c\u1ee7a Neuron 1        +    \u0110\u1ea7u ra c\u1ee7a Neuron 2        =       K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng\n  (d\u1ed1c l\u00ean t\u1eeb x=0.2)               (d\u1ed1c xu\u1ed1ng t\u1eeb x=0.8)                 (h\u00ecnh c\u00e1i l\u1ec1u)\n            /                                 |                               /\\\n           /                                  |                              /  \\\n          /                                   |                             /    \\\n---------+---------- (input)    --------------+---------- (input)   ---------+----+------ (input)\n       0.2                                  0.8                             0.2  0.8\n                                              \\\n                                               \\\n</code></pre> <p>\u0110\u00e2y ch\u00ednh l\u00e0 \"vi\u00ean g\u1ea1ch LEGO\" h\u00ecnh tam gi\u00e1c c\u1ee7a ch\u00fang ta! B\u1eb1ng c\u00e1ch \u0111i\u1ec1u ch\u1ec9nh weight v\u00e0 bias c\u1ee7a c\u1eb7p neuron n\u00e0y, ch\u00fang ta c\u00f3 th\u1ec3 ki\u1ec3m so\u00e1t: *   V\u1ecb tr\u00ed c\u1ee7a c\u00e1i l\u1ec1u (d\u1ecbch tr\u00e1i/ph\u1ea3i). *   Chi\u1ec1u cao c\u1ee7a c\u00e1i l\u1ec1u. *   \u0110\u1ed9 d\u1ed1c c\u1ee7a hai b\u00ean s\u01b0\u1eddn l\u1ec1u.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#xay-dung-song-sin-ghep-nhieu-vien-gach","title":"X\u00e2y D\u1ef1ng S\u00f3ng Sin - Gh\u00e9p Nhi\u1ec1u \"Vi\u00ean G\u1ea1ch\"","text":"<p>B\u00e2y gi\u1edd b\u1ea1n \u0111\u00e3 c\u00f3 nh\u1eefng \"vi\u00ean g\u1ea1ch h\u00ecnh l\u1ec1u\". Vi\u1ec7c x\u1ea5p x\u1ec9 m\u1ed9t \u0111\u01b0\u1eddng cong h\u00ecnh sin tr\u1edf n\u00ean \u0111\u01a1n gi\u1ea3n:</p> <p>B\u1ea1n ch\u1ec9 c\u1ea7n d\u00f9ng nhi\u1ec1u c\u1eb7p neuron, m\u1ed7i c\u1eb7p t\u1ea1o ra m\u1ed9t \"c\u00e1i l\u1ec1u\" \u0111\u1ec3 m\u00f4 ph\u1ecfng m\u1ed9t \u0111o\u1ea1n c\u1ee7a s\u00f3ng sin.</p> <ul> <li>C\u1eb7p neuron 1: T\u1ea1o ra \u0111o\u1ea1n d\u1ed1c l\u00ean \u0111\u1ea7u ti\u00ean c\u1ee7a s\u00f3ng sin.</li> <li>C\u1eb7p neuron 2: T\u1ea1o ra \u0111o\u1ea1n d\u1ed1c xu\u1ed1ng ti\u1ebfp theo.</li> <li>C\u1eb7p neuron 3: T\u1ea1o ra \u0111o\u1ea1n d\u1ed1c l\u00ean c\u1ee7a ph\u1ea7n \u00e2m.</li> <li>... v\u00e0 c\u1ee9 th\u1ebf.</li> </ul> <p>Qu\u00e1 tr\u00ecnh \"hand-tuning\" (ch\u1ec9nh tay) trong s\u00e1ch (t\u1eeb Fig 4.20 \u0111\u1ebfn 4.33) ch\u1ec9 l\u00e0 \u0111\u1ec3 minh h\u1ecda cho b\u1ea1n th\u1ea5y: *   \"\u00c0, n\u1ebfu t\u00f4i ch\u1ec9nh <code>weight</code> n\u00e0y, c\u00e1i d\u1ed1c n\u00e0y s\u1ebd cao h\u01a1n.\" *   \"N\u1ebfu t\u00f4i ch\u1ec9nh <code>bias</code> kia, c\u00e1i l\u1ec1u n\u00e0y s\u1ebd d\u1ecbch sang ph\u1ea3i.\" *   \"N\u1ebfu t\u00f4i d\u00f9ng <code>weight</code> \u00e2m \u1edf \u0111\u1ea7u ra, c\u00e1i l\u1ec1u s\u1ebd b\u1ecb l\u1eadt ng\u01b0\u1ee3c xu\u1ed1ng d\u01b0\u1edbi (t\u1ea1o ra \u0111\u00e1y c\u1ee7a s\u00f3ng sin).\"</p> <p>Minh h\u1ecda tr\u1eebu t\u01b0\u1ee3ng b\u1eb1ng ASCII:</p> Text Only<pre><code>   S\u00f3ng sin m\u1ee5c ti\u00eau:\n       __/ \\__\n      /     \\\n     /       \\\n            / \\\n    _______/   \\______\n\n   M\u1ea1ng neural x\u1ea5p x\u1ec9 b\u1eb1ng c\u00e1ch c\u1ed9ng c\u00e1c \"c\u00e1i l\u1ec1u\":\n\n     L\u1ec1u 1      L\u1ec1u 2 (l\u1eadt ng\u01b0\u1ee3c)     L\u1ec1u 3...\n       /\\               _                /\\\n      /  \\             / \\              /  \\\n     /    \\           /   \\            /    \\\n    -------  +      \\/     +  ...   =   K\u1ebft qu\u1ea3 g\u1ea7n gi\u1ed1ng s\u00f3ng sin\n</code></pre>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#tong-ket","title":"T\u1ed5ng K\u1ebft","text":"<ol> <li> <p>S\u1ee9c m\u1ea1nh c\u1ee7a ReLU: B\u1ea3n th\u00e2n ReLU r\u1ea5t \u0111\u01a1n gi\u1ea3n, nh\u01b0ng khi \u0111\u01b0\u1ee3c k\u1ebft h\u1ee3p trong m\u1ed9t m\u1ea1ng l\u01b0\u1edbi nhi\u1ec1u l\u1edbp, ch\u00fang c\u00f3 kh\u1ea3 n\u0103ng t\u1ea1o ra c\u00e1c h\u00e0m tuy\u1ebfn t\u00ednh t\u1eebng \u0111o\u1ea1n (piecewise linear) v\u00f4 c\u00f9ng ph\u1ee9c t\u1ea1p. Nh\u1eefng h\u00e0m n\u00e0y c\u00f3 th\u1ec3 x\u1ea5p x\u1ec9 b\u1ea5t k\u1ef3 h\u00e0m li\u00ean t\u1ee5c n\u00e0o (\u0111\u00e2y l\u00e0 \u00fd t\u01b0\u1edfng c\u1ee7a \u0110\u1ecbnh l\u00fd X\u1ea5p x\u1ec9 Ph\u1ed5 qu\u00e1t - Universal Approximation Theorem).</p> </li> <li> <p>T\u1ea1i sao c\u1ea7n nhi\u1ec1u l\u1edbp \u1ea9n? L\u1edbp \u1ea9n \u0111\u1ea7u ti\u00ean t\u1ea1o ra c\u00e1c \"\u0111o\u1ea1n d\u1ed1c\". L\u1edbp \u1ea9n th\u1ee9 hai k\u1ebft h\u1ee3p c\u00e1c \"\u0111o\u1ea1n d\u1ed1c\" \u0111\u00f3 \u0111\u1ec3 t\u1ea1o th\u00e0nh c\u00e1c \"c\u00e1i l\u1ec1u\". C\u00e1c l\u1edbp sau c\u00f3 th\u1ec3 k\u1ebft h\u1ee3p c\u00e1c \"c\u00e1i l\u1ec1u\" n\u00e0y th\u00e0nh nh\u1eefng h\u00ecnh d\u1ea1ng c\u00f2n ph\u1ee9c t\u1ea1p h\u01a1n n\u1eefa.</p> </li> <li> <p>T\u1eeb \"Ch\u1ec9nh Tay\" \u0111\u1ebfn \"T\u1ef1 H\u1ecdc\": Vi\u1ec7c ch\u1ec9nh tay c\u00e1c th\u00f4ng s\u1ed1 trong s\u00e1ch r\u1ea5t t\u1ed1n c\u00f4ng v\u00e0 ch\u1ec9 mang t\u00ednh minh h\u1ecda. Trong th\u1ef1c t\u1ebf, qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n (training) m\u1ea1ng neural ch\u00ednh l\u00e0 qu\u00e1 tr\u00ecnh m\u00e1y t\u00ednh t\u1ef1 \u0111\u1ed9ng t\u00ecm ra c\u00e1c gi\u00e1 tr\u1ecb <code>weight</code> v\u00e0 <code>bias</code> t\u1ed1t nh\u1ea5t cho t\u1ea5t c\u1ea3 c\u00e1c neuron, \u0111\u1ec3 k\u1ebft qu\u1ea3 \u0111\u1ea7u ra c\u1ee7a m\u1ea1ng kh\u1edbp v\u1edbi d\u1eef li\u1ec7u m\u1ee5c ti\u00eau nh\u1ea5t c\u00f3 th\u1ec3. B\u1ed9 t\u1ed1i \u01b0u h\u00f3a (optimizer) nh\u01b0 Gradient Descent ch\u00ednh l\u00e0 \"ki\u1ebfn tr\u00fac s\u01b0 tr\u01b0\u1edfng\" l\u00e0m c\u00f4ng vi\u1ec7c n\u00e0y.</p> </li> <li> <p>Nhi\u1ec1u Neuron H\u01a1n = T\u1ed1t H\u01a1n: khi t\u0103ng s\u1ed1 neuron l\u00ean, v\u00ed d\u1ee5: 64, m\u1ea1ng c\u00f3 nhi\u1ec1u \"vi\u00ean g\u1ea1ch\" h\u01a1n \u0111\u1ec3 x\u00e2y d\u1ef1ng. K\u1ebft qu\u1ea3 l\u00e0 \u0111\u01b0\u1eddng cong x\u1ea5p x\u1ec9 tr\u00f4ng m\u01b0\u1ee3t m\u00e0 v\u00e0 ch\u00ednh x\u00e1c h\u01a1n r\u1ea5t nhi\u1ec1u.</p> </li> </ol> <p>ReLU, d\u00f9 \u0111\u01a1n gi\u1ea3n, l\u1ea1i l\u00e0 n\u1ec1n t\u1ea3ng cho s\u1ee9c m\u1ea1nh phi th\u01b0\u1eddng c\u1ee7a m\u1ea1ng neural hi\u1ec7n \u0111\u1ea1i.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#phan-2-i-sau-vao-qua-trinh-bien-oi-mot-iem-du-lieu-duy-nhat","title":"Ph\u1ea7n 2: \u0110i s\u00e2u v\u00e0o qu\u00e1 tr\u00ecnh bi\u1ebfn \u0111\u1ed5i m\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u duy nh\u1ea5t.","text":"<p>Gi\u1ea3 s\u1eed ch\u00fang ta c\u00f3:</p> <ul> <li>M\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o <code>O</code> c\u00f3 t\u1ecda \u0111\u1ed9 <code>(0.5, 1.0)</code>.</li> <li>M\u1ed9t l\u1edbp <code>Layer_Dense</code> c\u00f3 2 \u0111\u1ea7u v\u00e0o v\u00e0 3 neuron.</li> </ul>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#1-khoi-tao-initialization","title":"1. Kh\u1edfi T\u1ea1o (Initialization)","text":"<p>L\u1edbp <code>dense1</code> \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o v\u1edbi <code>weights</code> v\u00e0 <code>biases</code>. Gi\u1ea3 s\u1eed sau khi kh\u1edfi t\u1ea1o ng\u1eabu nhi\u00ean, ch\u00fang ta c\u00f3 c\u00e1c gi\u00e1 tr\u1ecb c\u1ee5 th\u1ec3 nh\u01b0 sau:</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#ma-tran-trong-so-w-selfweights-kich-thuoc-2-3","title":"Ma tr\u1eadn Tr\u1ecdng s\u1ed1 <code>W</code> (self.weights) - K\u00edch th\u01b0\u1edbc (2, 3)","text":"<ul> <li>H\u00e0ng 0: Tr\u1ecdng s\u1ed1 cho \u0111\u1ea7u v\u00e0o th\u1ee9 nh\u1ea5t (<code>i1 = 0.5</code>).</li> <li>H\u00e0ng 1: Tr\u1ecdng s\u1ed1 cho \u0111\u1ea7u v\u00e0o th\u1ee9 hai (<code>i2 = 1.0</code>).</li> <li>C\u1ed9t 0, 1, 2: T\u01b0\u01a1ng \u1ee9ng v\u1edbi Neuron 0, 1, 2.</li> </ul> Text Only<pre><code>          Neuron 0   Neuron 1   Neuron 2\n         +----------+----------+----------+\nInput 0  |   0.2    |   0.8    |  -0.5    |\n(i1=0.5) +----------+----------+----------+\nInput 1  |  -0.9    |   0.2    |   0.4    |\n(i2=1.0) +----------+----------+----------+\n</code></pre>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#vector-bias-b-selfbiases-kich-thuoc-1-3","title":"Vector Bias <code>b</code> (self.biases) - K\u00edch th\u01b0\u1edbc (1, 3)","text":"<ul> <li>M\u1ed7i gi\u00e1 tr\u1ecb t\u01b0\u01a1ng \u1ee9ng v\u1edbi thi\u00ean ki\u1ebfn c\u1ee7a m\u1ed9t neuron.</li> </ul> Text Only<pre><code>         +----------+----------+----------+\n         |   2.0    |   3.0    |   0.5    |\n         +----------+----------+----------+\n           Neuron 0   Neuron 1   Neuron 2\n</code></pre>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#2-qua-trinh-bien-oi-transformation-dense1forwardo","title":"2. Qu\u00e1 tr\u00ecnh Bi\u1ebfn \u0111\u1ed5i (Transformation) - <code>dense1.forward(O)</code>","text":"<p>Ch\u00fang ta th\u1ef1c hi\u1ec7n ph\u00e9p to\u00e1n: <code>v' = v \u00b7 W + b</code></p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#buoc-21-phep-nhan-ma-tran-dot-product-v-w","title":"B\u01b0\u1edbc 2.1: Ph\u00e9p nh\u00e2n ma tr\u1eadn (Dot Product) <code>v \u00b7 W</code>","text":"<ul> <li><code>v</code> l\u00e0 vector \u0111\u1ea7u v\u00e0o: <code>[0.5, 1.0]</code> (K\u00edch th\u01b0\u1edbc 1x2)</li> <li><code>W</code> l\u00e0 ma tr\u1eadn tr\u1ecdng s\u1ed1 (K\u00edch th\u01b0\u1edbc 2x3)</li> <li>K\u1ebft qu\u1ea3 s\u1ebd l\u00e0 m\u1ed9t vector k\u00edch th\u01b0\u1edbc 1x3.</li> </ul> Text Only<pre><code>                                       +-------+-------+-------+\n                                       |  0.2  |  0.8  | -0.5  |\n                                       | -0.9  |  0.2  |  0.4  |\n                                       +-------+-------+-------+\n                                                 ^\n                                                 |\n                                                 \u00b7 (Dot Product)\n+-------+-------+\n|  0.5  |  1.0  |\n+-------+-------+\n      |\n      +-------------------------------------------------------------+\n      |                                                             |\n      v                                                             v\n    T\u00ednh to\u00e1n cho Neuron 0:                                       T\u00ednh to\u00e1n cho Neuron 1:\n    (0.5 * 0.2) + (1.0 * -0.9)                                    (0.5 * 0.8) + (1.0 * 0.2)\n    = 0.1 - 0.9                                                   = 0.4 + 0.2\n    = -0.8                                                        = 0.6\n\n                                                                     T\u00ednh to\u00e1n cho Neuron 2:\n                                                                     (0.5 * -0.5) + (1.0 * 0.4)\n                                                                     = -0.25 + 0.4\n                                                                     = 0.15\n</code></pre> <p>K\u1ebft qu\u1ea3 c\u1ee7a ph\u00e9p nh\u00e2n ma tr\u1eadn l\u00e0 vector <code>[-0.8, 0.6, 0.15]</code>.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#buoc-22-cong-vector-bias-b","title":"B\u01b0\u1edbc 2.2: C\u1ed9ng Vector Bias <code>+ b</code>","text":"<p>B\u00e2y gi\u1edd, ch\u00fang ta l\u1ea5y k\u1ebft qu\u1ea3 \u1edf tr\u00ean v\u00e0 c\u1ed9ng v\u1edbi vector bias.</p> Text Only<pre><code>      K\u1ebft qu\u1ea3 t\u1eeb v \u00b7 W                  Vector Bias b                Vector \u0111\u1ea7u ra v'\n+--------+-------+--------+     +     +-------+-------+-------+     =     +-------+-------+-------+\n|  -0.8  |  0.6  |  0.15  |           |  2.0  |  3.0  |  0.5  |           |  1.2  |  3.6  |  0.65 |\n+--------+-------+--------+           +-------+-------+-------+           +-------+-------+-------+\n     |        |        |                 |        |        |                 |        |        |\n     |        |        +-----------------|--------|--------|-----------------+        |\n     |        +--------------------------|--------|--------+--------------------------+\n     +-----------------------------------|--------+-----------------------------------+\n\n     -0.8 + 2.0 = 1.2\n           0.6 + 3.0 = 3.6\n                 0.15 + 0.5 = 0.65\n</code></pre> <p>K\u1ebft qu\u1ea3: Vector <code>v'</code> (\u0111\u1ea7u ra c\u1ee7a <code>dense1</code>) l\u00e0 <code>[1.2, 3.6, 0.65]</code>. \u0110\u00e2y ch\u00ednh l\u00e0 t\u1ecda \u0111\u1ed9 c\u1ee7a \u0111i\u1ec3m <code>O</code> trong kh\u00f4ng gian 3 chi\u1ec1u m\u1edbi sau ph\u00e9p bi\u1ebfn \u0111\u1ed5i tuy\u1ebfn t\u00ednh.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#3-kich-hoat-relu-activation1forwardv","title":"3. K\u00edch Ho\u1ea1t ReLU - <code>activation1.forward(v')</code>","text":"<p>B\u00e2y gi\u1edd, ch\u00fang ta \u0111\u01b0a vector <code>v'</code> qua h\u00e0m ReLU. H\u00e0m n\u00e0y ho\u1ea1t \u0111\u1ed9ng tr\u00ean t\u1eebng ph\u1ea7n t\u1eed (element-wise).</p> Text Only<pre><code>     Vector \u0111\u1ea7u v\u00e0o v' cho ReLU           H\u00e0nh \u0111\u1ed9ng c\u1ee7a ReLU           Vector cu\u1ed1i c\u00f9ng v''\n+-------+-------+-------+        max(0, x)       +-------+-------+-------+\n|  1.2  |  3.6  |  0.65 |  ----------------&gt;     |  1.2  |  3.6  |  0.65 |\n+-------+-------+-------+                        +-------+-------+-------+\n     |        |        |\n     |        |        +-----&gt; max(0, 0.65) = 0.65\n     |        +--------------&gt; max(0, 3.6)  = 3.6\n     +-----------------------&gt; max(0, 1.2)  = 1.2\n</code></pre> <p>Trong v\u00ed d\u1ee5 n\u00e0y, v\u00ec t\u1ea5t c\u1ea3 c\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a <code>v'</code> \u0111\u1ec1u l\u00e0 s\u1ed1 d\u01b0\u01a1ng, n\u00ean \u0111\u1ea7u ra c\u1ee7a ReLU <code>v''</code> gi\u1ed1ng h\u1ec7t <code>v'</code>.</p> <p>N\u1ebfu <code>v'</code> l\u00e0 <code>[-0.8, 0.6, 0.15]</code> (tr\u01b0\u1edbc khi c\u1ed9ng bias), th\u00ec k\u1ebft qu\u1ea3 s\u1ebd kh\u00e1c:</p> Text Only<pre><code>     Vector \u0111\u1ea7u v\u00e0o v' cho ReLU           H\u00e0nh \u0111\u1ed9ng c\u1ee7a ReLU           Vector cu\u1ed1i c\u00f9ng v''\n+--------+-------+--------+        max(0, x)       +-------+-------+--------+\n|  -0.8  |  0.6  |  0.15  |  ----------------&gt;     |  0.0  |  0.6  |  0.15  |\n+--------+-------+--------+                        +-------+-------+--------+\n     |        |        |\n     |        |        +-----&gt; max(0, 0.15) = 0.15\n     |        +--------------&gt; max(0, 0.6)  = 0.6\n     +-----------------------&gt; max(0, -0.8) = 0.0\n</code></pre> <p>S\u01a1 \u0111\u1ed3 n\u00e0y \u0111\u00e3 m\u00f4 t\u1ea3 to\u00e0n b\u1ed9 qu\u00e1 tr\u00ecnh to\u00e1n h\u1ecdc t\u1eeb m\u1ed9t vector \u0111\u1ea7u v\u00e0o <code>v</code> \u0111\u1ebfn vector cu\u1ed1i c\u00f9ng <code>v''</code> sau khi qua m\u1ed9t l\u1edbp d\u00e0y \u0111\u1eb7c v\u00e0 m\u1ed9t l\u1edbp k\u00edch ho\u1ea1t ReLU.</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#truu-tuong-hoa","title":"Tr\u1eebu t\u01b0\u1ee3ng h\u00f3a","text":"<p>M\u1ed7i neuron \u0111\u00f3ng g\u00f3p v\u00e0o vi\u1ec7c t\u1ea1o ra \"ch\u1eef k\u00fd\" cu\u1ed1i c\u00f9ng nh\u01b0 th\u1ebf n\u00e0o?</p>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#phan-tich","title":"Ph\u00e2n T\u00edch","text":"<ol> <li> <p>Neural 1 \u0111\u00f3ng g\u00f3p m\u1ed9t ph\u1ea7n v\u00e0o vi\u1ec7c t\u1ea1o ra ch\u1eef k\u00fd cu\u1ed1i c\u00f9ng. N\u00f3 gi\u1ed1ng nh\u01b0 m\u1ed9t nh\u1ea1c c\u00f4ng trong d\u00e0n nh\u1ea1c. Nh\u1ea1c c\u00f4ng violin kh\u00f4ng \"mang\" b\u1ea3n giao h\u01b0\u1edfng, anh ta ch\u1ec9 ch\u01a1i ph\u1ea7n violin c\u1ee7a m\u00ecnh. B\u1ea3n giao h\u01b0\u1edfng (ch\u1eef k\u00fd) l\u00e0 s\u1ef1 k\u1ebft h\u1ee3p c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c nh\u1ea1c c\u00f4ng. C\u00e1ch di\u1ec5n \u0111\u1ea1t ch\u00ednh x\u00e1c h\u01a1n: \"Neuron 1 c\u00f3 m\u1ed9t b\u1ed9 ti\u00eau ch\u00ed ri\u00eang (weights v\u00e0 bias c\u1ee7a n\u00f3).\"</p> </li> <li> <p>\"bi\u1ebfn \u0111\u1ed5i O(x,y) --&gt; O'(x,y,z)\": To\u00e0n b\u1ed9 l\u1edbp (g\u1ed3m c\u1ea3 3 neuron) c\u00f9ng nhau th\u1ef1c hi\u1ec7n ph\u00e9p bi\u1ebfn \u0111\u1ed5i n\u00e0y.</p> </li> </ol>"},{"location":"Explain%20Documents/02-transformation_relu_math_explain/#dien-giai","title":"Di\u1ec5n Gi\u1ea3i","text":"<ol> <li> <p>M\u1ed7i Neuron l\u00e0 m\u1ed9t \"M\u00e1y \u0110o \u0110\u1eb7c Tr\u01b0ng\":</p> <ul> <li>Neuron 1 \u0111\u01b0\u1ee3c trang b\u1ecb m\u1ed9t b\u1ed9 ti\u00eau ch\u00ed <code>(w1, b1)</code>. N\u00f3 \u0111o xem \u0111i\u1ec3m <code>O(x,y)</code> ph\u00f9 h\u1ee3p v\u1edbi ti\u00eau ch\u00ed n\u00e0y \u0111\u1ebfn \u0111\u00e2u v\u00e0 cho ra m\u1ed9t \u0111i\u1ec3m s\u1ed1 l\u00e0 <code>x'</code>.</li> <li>Neuron 2 \u0111\u01b0\u1ee3c trang b\u1ecb m\u1ed9t b\u1ed9 ti\u00eau ch\u00ed <code>(w2, b2)</code>. N\u00f3 \u0111o xem \u0111i\u1ec3m <code>O(x,y)</code> ph\u00f9 h\u1ee3p v\u1edbi ti\u00eau ch\u00ed n\u00e0y \u0111\u1ebfn \u0111\u00e2u v\u00e0 cho ra m\u1ed9t \u0111i\u1ec3m s\u1ed1 l\u00e0 <code>y'</code>.</li> <li>Neuron 3 \u0111\u01b0\u1ee3c trang b\u1ecb m\u1ed9t b\u1ed9 ti\u00eau ch\u00ed <code>(w3, b3)</code>. N\u00f3 \u0111o xem \u0111i\u1ec3m <code>O(x,y)</code> ph\u00f9 h\u1ee3p v\u1edbi ti\u00eau ch\u00ed n\u00e0y \u0111\u1ebfn \u0111\u00e2u v\u00e0 cho ra m\u1ed9t \u0111i\u1ec3m s\u1ed1 l\u00e0 <code>z'</code>.</li> </ul> </li> <li> <p>T\u1ea1o Ra \"Ch\u1eef K\u00fd\":</p> <ul> <li>\"Ch\u1eef k\u00fd\" c\u1ee7a \u0111i\u1ec3m <code>O</code> kh\u00f4ng ph\u1ea3i l\u00e0 do m\u1ed9t neuron t\u1ea1o ra. \"Ch\u1eef k\u00fd\" ch\u00ednh l\u00e0 vector k\u1ebft qu\u1ea3 <code>O'(x', y', z')</code>. N\u00f3 l\u00e0 t\u1eadp h\u1ee3p c\u00e1c \u0111i\u1ec3m s\u1ed1 m\u00e0 t\u1ea5t c\u1ea3 c\u00e1c \"m\u00e1y \u0111o\" \u0111\u00e3 \u0111\u01b0a ra.</li> </ul> </li> <li> <p>M\u1ee5c Ti\u00eau Hu\u1ea5n Luy\u1ec7n (Training):</p> <ul> <li>Qu\u00e1 tr\u00ecnh hu\u1ea5n luy\u1ec7n s\u1ebd \u0111i\u1ec1u ch\u1ec9nh c\u00e1c b\u1ed9 ti\u00eau ch\u00ed <code>(w, b)</code> c\u1ee7a t\u1eebng neuron sao cho:<ul> <li>T\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m <code>O</code> thu\u1ed9c l\u1edbp \"Xanh\" khi \u0111i qua 3 \"m\u00e1y \u0111o\" n\u00e0y s\u1ebd t\u1ea1o ra c\u00e1c vector <code>O'</code> (c\u00e1c ch\u1eef k\u00fd) n\u1eb1m g\u1ea7n nhau trong m\u1ed9t v\u00f9ng kh\u00f4ng gian.</li> <li>T\u1ea5t c\u1ea3 c\u00e1c \u0111i\u1ec3m <code>O</code> thu\u1ed9c l\u1edbp \"\u0110\u1ecf\" s\u1ebd t\u1ea1o ra c\u00e1c ch\u1eef k\u00fd n\u1eb1m g\u1ea7n nhau trong m\u1ed9t v\u00f9ng kh\u00f4ng gian kh\u00e1c.</li> <li>V\u00e0 t\u01b0\u01a1ng t\u1ef1 cho l\u1edbp \"L\u00e1\".</li> </ul> </li> </ul> </li> </ol> <p>S\u01a1 \u0110\u1ed3 ASCII Ph\u1ea3n \u00c1nh \u00dd T\u01b0\u1edfng N\u00e0y</p> Text Only<pre><code>  \u0110i\u1ec3m \u0110\u1ea7u V\u00e0o O(x,y)\n          |\n          |\n+---------+---------+\n|                   |\nv                   v\nM\u00e1y \u0110o 1            M\u00e1y \u0110o 2            M\u00e1y \u0110o 3\n(Ti\u00eau ch\u00ed w1, b1)   (Ti\u00eau ch\u00ed w2, b2)   (Ti\u00eau ch\u00ed w3, b3)\n|                   |                   |\nv                   v                   v\n\u0110i\u1ec3m s\u1ed1 x'          \u0110i\u1ec3m s\u1ed1 y'          \u0110i\u1ec3m s\u1ed1 z'\n|                   |                   |\n+---------+---------+-------------------+\n          |\n          v\n\"Ch\u1eef K\u00fd\" = O'(x', y', z')\n(Vector k\u1ebft qu\u1ea3 trong kh\u00f4ng gian m\u1edbi)\n</code></pre> <p>V\u00ed d\u1ee5: Sau khi hu\u1ea5n luy\u1ec7n, c\u00f3 th\u1ec3 x\u1ea3y ra tr\u01b0\u1eddng h\u1ee3p:</p> <ul> <li>Ti\u00eau ch\u00ed 1 (c\u1ee7a Neuron 1) tr\u1edf th\u00e0nh \"ph\u00e1t hi\u1ec7n \u0111\u01b0\u1eddng cong h\u01b0\u1edbng l\u00ean\".</li> <li>Ti\u00eau ch\u00ed 2 (c\u1ee7a Neuron 2) tr\u1edf th\u00e0nh \"ph\u00e1t hi\u1ec7n v\u1ecb tr\u00ed g\u1ea7n g\u1ed1c t\u1ecda \u0111\u1ed9\".</li> <li>M\u1ed9t \u0111i\u1ec3m <code>O</code> thu\u1ed9c l\u1edbp \"Xanh\" c\u00f3 th\u1ec3 v\u1eeba cong l\u00ean, v\u1eeba g\u1ea7n g\u1ed1c t\u1ecda \u0111\u1ed9. Ch\u1eef k\u00fd c\u1ee7a n\u00f3 s\u1ebd l\u00e0 <code>O'(CAO, CAO, ...)</code>.</li> <li>M\u1ed9t \u0111i\u1ec3m <code>O</code> thu\u1ed9c l\u1edbp \"\u0110\u1ecf\" c\u00f3 th\u1ec3 cong l\u00ean nh\u01b0ng xa g\u1ed1c t\u1ecda \u0111\u1ed9. Ch\u1eef k\u00fd c\u1ee7a n\u00f3 s\u1ebd l\u00e0 <code>O'(CAO, TH\u1ea4P, ...)</code>.</li> </ul> <p>K\u1ebft lu\u1eadn: M\u1ed7i neuron c\u00f3 m\u1ed9t vai tr\u00f2 ri\u00eang. Vai tr\u00f2 \u0111\u00f3 l\u00e0 \"\u0111o l\u01b0\u1eddng m\u1ed9t \u0111\u1eb7c tr\u01b0ng\". \"Ch\u1eef k\u00fd\" cu\u1ed1i c\u00f9ng c\u1ee7a m\u1ed9t \u0111i\u1ec3m d\u1eef li\u1ec7u l\u00e0 t\u1ed5 h\u1ee3p k\u1ebft qu\u1ea3 t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c ph\u00e9p \u0111o \u0111\u1eb7c tr\u01b0ng \u0111\u00f3.</p>"},{"location":"Explain%20Documents/03-softmax_explain/","title":"Ch4pt3r.03 - Softmax","text":""},{"location":"Explain%20Documents/03-softmax_explain/#giai-thich-ve-softmax-trong-neural-network","title":"Gi\u1ea3i th\u00edch v\u1ec1 Softmax trong Neural Network","text":""},{"location":"Explain%20Documents/03-softmax_explain/#phan-1-tai-sao-chung-ta-can-softmax-van-e-la-gi","title":"Ph\u1ea7n 1: T\u1ea1i sao ch\u00fang ta c\u1ea7n Softmax? V\u1ea5n \u0111\u1ec1 l\u00e0 g\u00ec?","text":"<p>\u1ede c\u00e1c ch\u01b0\u01a1ng tr\u01b0\u1edbc, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u00e3 l\u00e0m quen v\u1edbi h\u00e0m k\u00edch ho\u1ea1t ReLU (Rectified Linear Unit). ReLU r\u1ea5t t\u1ed1t cho c\u00e1c l\u1edbp \u1ea9n (hidden layers) nh\u01b0ng l\u1ea1i c\u00f3 m\u1ed9t v\u00e0i v\u1ea5n \u0111\u1ec1 n\u1ebfu d\u00f9ng cho l\u1edbp cu\u1ed1i c\u00f9ng (output layer) c\u1ee7a m\u1ed9t m\u1ea1ng ph\u00e2n lo\u1ea1i:</p> <ol> <li>Kh\u00f4ng b\u1ecb ch\u1eb7n (Unbounded): \u0110\u1ea7u ra c\u1ee7a ReLU c\u00f3 th\u1ec3 l\u00e0 b\u1ea5t k\u1ef3 s\u1ed1 d\u01b0\u01a1ng n\u00e0o (v\u00ed d\u1ee5: <code>[12, 99, 318]</code>). Nh\u1eefng con s\u1ed1 n\u00e0y \u0111\u1ee9ng m\u1ed9t m\u00ecnh kh\u00f4ng c\u00f3 nhi\u1ec1u \u00fd ngh\u0129a. 318 l\u1edbn h\u01a1n 99, nh\u01b0ng l\u1edbn h\u01a1n \"bao nhi\u00eau\"? Li\u1ec7u n\u00f3 c\u00f3 \"ch\u1eafc ch\u1eafn\" h\u01a1n nhi\u1ec1u kh\u00f4ng? Ch\u00fang ta kh\u00f4ng c\u00f3 m\u1ed9t \"ng\u1eef c\u1ea3nh\" \u0111\u1ec3 so s\u00e1nh.</li> <li>Kh\u00f4ng \u0111\u01b0\u1ee3c chu\u1ea9n h\u00f3a (Not Normalized): C\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u ra kh\u00f4ng c\u00f3 m\u1ed1i li\u00ean h\u1ec7 t\u1ed5ng th\u1ec3. T\u1ed5ng c\u1ee7a ch\u00fang kh\u00f4ng b\u1eb1ng m\u1ed9t con s\u1ed1 c\u1ed1 \u0111\u1ecbnh n\u00e0o c\u1ea3.</li> <li>\u0110\u1ed9c quy\u1ec1n (Exclusive): \u0110\u1ea7u ra c\u1ee7a m\u1ed7i neuron l\u00e0 \u0111\u1ed9c l\u1eadp v\u1edbi c\u00e1c neuron kh\u00e1c.</li> </ol> <p>M\u1ee5c ti\u00eau c\u1ee7a ch\u00fang ta: V\u1edbi b\u00e0i to\u00e1n ph\u00e2n lo\u1ea1i, ch\u00fang ta mu\u1ed1n m\u1ea1ng n\u01a1-ron \"n\u00f3i\" cho ch\u00fang ta bi\u1ebft n\u00f3 \"ngh\u0129\" r\u1eb1ng \u0111\u1ea7u v\u00e0o thu\u1ed9c v\u1ec1 l\u1edbp n\u00e0o v\u1edbi m\u1ed9t m\u1ee9c \u0111\u1ed9 t\u1ef1 tin (confidence) r\u00f5 r\u00e0ng. V\u00ed d\u1ee5, v\u1edbi 3 l\u1edbp (ch\u00f3, m\u00e8o, chim), ch\u00fang ta mu\u1ed1n \u0111\u1ea7u ra c\u00f3 d\u1ea1ng nh\u01b0 <code>[0.05, 0.9, 0.05]</code>, ngh\u0129a l\u00e0: \"T\u00f4i tin ch\u1eafc 90% \u0111\u00e2y l\u00e0 m\u00e8o, 5% l\u00e0 ch\u00f3 v\u00e0 5% l\u00e0 chim.\"</p> <p>=&gt; Softmax ra \u0111\u1eddi \u0111\u1ec3 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 n\u00e0y. N\u00f3 nh\u1eadn v\u00e0o c\u00e1c s\u1ed1 th\u1ef1c b\u1ea5t k\u1ef3 (c\u00f3 th\u1ec3 \u00e2m, d\u01b0\u01a1ng, l\u1edbn, nh\u1ecf) v\u00e0 bi\u1ebfn ch\u00fang th\u00e0nh m\u1ed9t ph\u00e2n ph\u1ed1i x\u00e1c su\u1ea5t (probability distribution). C\u00e1c \u0111\u1eb7c \u0111i\u1ec3m c\u1ee7a ph\u00e2n ph\u1ed1i x\u00e1c su\u1ea5t n\u00e0y l\u00e0: *   T\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u ra \u0111\u1ec1u n\u1eb1m trong kho\u1ea3ng <code>[0, 1]</code>. *   T\u1ed5ng c\u1ee7a t\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u ra lu\u00f4n b\u1eb1ng 1.</p> <p>Nh\u1eefng gi\u00e1 tr\u1ecb n\u00e0y ch\u00ednh l\u00e0 \u0111i\u1ec3m t\u1ef1 tin (confidence scores) m\u00e0 ch\u00fang ta c\u1ea7n.</p>"},{"location":"Explain%20Documents/03-softmax_explain/#muc-2-giai-phau-cong-thuc-softmax","title":"M\u1ee5c 2: \"Gi\u1ea3i ph\u1eabu\" c\u00f4ng th\u1ee9c Softmax","text":"<p>C\u00f4ng th\u1ee9c trong s\u00e1ch c\u00f3 v\u1ebb \u0111\u00e1ng s\u1ee3:</p> \\[ S_{i,j} = \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{L} e^{z_{i,l}}} \\] <p>\u0110\u1eebng lo, h\u00e3y chia n\u00f3 th\u00e0nh 2 b\u01b0\u1edbc c\u1ef1c k\u1ef3 \u0111\u01a1n gi\u1ea3n:</p> <p>B\u01b0\u1edbc 1: L\u0169y th\u1eeba h\u00f3a (Exponentiation) - T\u1eed s\u1ed1 <code>e^z</code></p> <ul> <li><code>z</code> l\u00e0 c\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u ra t\u1eeb l\u1edbp tr\u01b0\u1edbc (v\u00ed d\u1ee5 <code>layer_outputs = [4.8, 1.21, 2.385]</code>).</li> <li><code>e</code> l\u00e0 h\u1eb1ng s\u1ed1 Euler (x\u1ea5p x\u1ec9 2.71828), l\u00e0 c\u01a1 s\u1ed1 c\u1ee7a logarit t\u1ef1 nhi\u00ean.</li> <li>\"L\u0169y th\u1eeba h\u00f3a\" \u0111\u01a1n gi\u1ea3n l\u00e0 l\u1ea5y <code>e</code> m\u0169 c\u00e1c gi\u00e1 tr\u1ecb <code>z</code> \u0111\u00f3. Trong Python, ch\u00fang ta d\u00f9ng <code>E ** output</code> ho\u1eb7c <code>math.exp(output)</code>.</li> </ul> Python<pre><code># V\u00ed d\u1ee5 t\u1eeb s\u00e1ch\nlayer_outputs = [4.8, 1.21, 2.385]\nE = 2.71828182846\n\n# T\u00ednh e^z cho m\u1ed7i gi\u00e1 tr\u1ecb\nexp_values = [E**4.8, E**1.21, E**2.385] \n# K\u1ebft qu\u1ea3: [121.51, 3.35, 10.86]\n</code></pre> <p>T\u1ea1i sao ph\u1ea3i l\u00e0m b\u01b0\u1edbc n\u00e0y? 1.  Lo\u1ea1i b\u1ecf s\u1ed1 \u00e2m: <code>e</code> m\u0169 b\u1ea5t c\u1ee9 s\u1ed1 n\u00e0o c\u0169ng lu\u00f4n cho ra k\u1ebft qu\u1ea3 d\u01b0\u01a1ng. \u0110i\u1ec1u n\u00e0y r\u1ea5t quan tr\u1ecdng v\u00ec x\u00e1c su\u1ea5t kh\u00f4ng th\u1ec3 l\u00e0 s\u1ed1 \u00e2m. 2.  Khu\u1ebfch \u0111\u1ea1i s\u1ef1 kh\u00e1c bi\u1ec7t: H\u00e0m m\u0169 l\u00e0m cho c\u00e1c gi\u00e1 tr\u1ecb l\u1edbn c\u00e0ng l\u1edbn h\u01a1n m\u1ed9t c\u00e1ch v\u01b0\u1ee3t tr\u1ed9i so v\u1edbi c\u00e1c gi\u00e1 tr\u1ecb nh\u1ecf. Gi\u00e1 tr\u1ecb <code>4.8</code> ch\u1ec9 l\u1edbn h\u01a1n <code>2.385</code> kho\u1ea3ng 2 l\u1ea7n, nh\u01b0ng sau khi l\u0169y th\u1eeba, <code>121.51</code> l\u1edbn h\u01a1n <code>10.86</code> t\u1edbi h\u01a1n 11 l\u1ea7n! \u0110i\u1ec1u n\u00e0y gi\u00fap m\u1ea1ng \"t\u1ef1 tin\" h\u01a1n v\u00e0o d\u1ef1 \u0111o\u00e1n c\u00f3 \u0111i\u1ec3m s\u1ed1 cao nh\u1ea5t.</p> <p>B\u01b0\u1edbc 2: Chu\u1ea9n h\u00f3a (Normalization) - Ph\u00e9p chia</p> <p>Sau khi c\u00f3 c\u00e1c gi\u00e1 tr\u1ecb \u0111\u00e3 \u0111\u01b0\u1ee3c l\u0169y th\u1eeba (<code>exp_values</code>), ch\u00fang ta ch\u1ec9 c\u1ea7n l\u00e0m m\u1ed9t vi\u1ec7c:</p> <ol> <li>T\u00ednh t\u1ed5ng t\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb \u0111\u00f3 (m\u1eabu s\u1ed1 \\(\\sum_{l=1}^{L} e^{z_{i,l}}\\)).</li> <li>L\u1ea5y t\u1eebng gi\u00e1 tr\u1ecb chia cho t\u1ed5ng v\u1eeba t\u00ednh \u0111\u01b0\u1ee3c.</li> </ol> Python<pre><code># Ti\u1ebfp n\u1ed1i v\u00ed d\u1ee5 tr\u00ean\nexp_values = [121.51, 3.35, 10.86]\n\n# 1. T\u00ednh t\u1ed5ng\nnorm_base = sum(exp_values) # 121.51 + 3.35 + 10.86 = 135.72\n\n# 2. Chia t\u1eebng gi\u00e1 tr\u1ecb cho t\u1ed5ng\nnorm_values = [\n    121.51 / norm_base, # ~0.895\n    3.35 / norm_base,   # ~0.025\n    10.86 / norm_base   # ~0.080\n]\n\n# K\u1ebft qu\u1ea3: [0.895, 0.025, 0.080]\n# Ki\u1ec3m tra: 0.895 + 0.025 + 0.080 = 1.0\n</code></pre> <p>V\u1eady l\u00e0 xong! Ch\u00fang ta \u0111\u00e3 bi\u1ebfn <code>[4.8, 1.21, 2.385]</code> th\u00e0nh m\u1ed9t ph\u00e2n ph\u1ed1i x\u00e1c su\u1ea5t <code>[0.895, 0.025, 0.080]</code>.</p>"},{"location":"Explain%20Documents/03-softmax_explain/#muc-3-toi-uu-voi-numpy-va-xu-ly-theo-lo-batch","title":"M\u1ee5c 3: T\u1ed1i \u01b0u v\u1edbi NumPy v\u00e0 x\u1eed l\u00fd theo L\u00f4 (Batch)","text":"<p>Trong th\u1ef1c t\u1ebf, ch\u00fang ta kh\u00f4ng x\u1eed l\u00fd t\u1eebng m\u1eabu d\u1eef li\u1ec7u m\u1ed9t m\u00e0 x\u1eed l\u00fd c\u1ea3 m\u1ed9t l\u00f4 (batch) \u0111\u1ec3 t\u0103ng t\u1ed1c \u0111\u1ed9. M\u1ed9t l\u00f4 d\u1eef li\u1ec7u s\u1ebd c\u00f3 d\u1ea1ng m\u1ed9t ma tr\u1eadn, trong \u0111\u00f3 m\u1ed7i h\u00e0ng l\u00e0 \u0111\u1ea7u ra cho m\u1ed9t m\u1eabu.</p> Python<pre><code># M\u1ed9t l\u00f4 c\u00f3 3 m\u1eabu, m\u1ed7i m\u1eabu c\u00f3 3 \u0111\u1ea7u ra\nlayer_outputs = np.array([[4.8, 1.21, 2.385],\n                          [8.9, -1.81, 0.2],\n                          [1.41, 1.051, 0.026]])\n</code></pre> <p>B\u00e2y gi\u1edd, ch\u00fang ta c\u1ea7n t\u00ednh Softmax cho t\u1eebng h\u00e0ng m\u1ed9t. \u0110\u00e2y l\u00e0 l\u00fac c\u00e1c tham s\u1ed1 <code>axis</code> v\u00e0 <code>keepdims</code> c\u1ee7a NumPy ph\u00e1t huy t\u00e1c d\u1ee5ng.</p> <ul> <li><code>np.exp(layer_outputs)</code>: NumPy th\u00f4ng minh s\u1ebd t\u1ef1 \u0111\u1ed9ng t\u00ednh l\u0169y th\u1eeba cho m\u1ecdi ph\u1ea7n t\u1eed trong ma tr\u1eadn.</li> <li><code>np.sum(..., axis=1)</code>: Ch\u00fang ta c\u1ea7n t\u00ednh t\u1ed5ng c\u1ee7a c\u00e1c gi\u00e1 tr\u1ecb tr\u00ean m\u1ed7i h\u00e0ng.<ul> <li><code>axis=0</code>: t\u00ednh t\u1ed5ng theo c\u1ed9t.</li> <li><code>axis=1</code>: t\u00ednh t\u1ed5ng theo h\u00e0ng. \u0110\u00e2y l\u00e0 c\u00e1i ch\u00fang ta c\u1ea7n.</li> </ul> </li> <li><code>keepdims=True</code>: Khi t\u00ednh t\u1ed5ng theo <code>axis=1</code>, k\u1ebft qu\u1ea3 s\u1ebd l\u00e0 m\u1ed9t vector h\u00e0ng <code>[8.395, 7.29, 2.487]</code>. N\u1ebfu ch\u00fang ta l\u1ea5y ma tr\u1eadn <code>(3, 3)</code> chia cho vector <code>(3,)</code>, NumPy c\u00f3 th\u1ec3 b\u00e1o l\u1ed7i ho\u1eb7c kh\u00f4ng th\u1ef1c hi\u1ec7n \u0111\u00fang ph\u00e9p chia theo h\u00e0ng. <code>keepdims=True</code> s\u1ebd gi\u1eef nguy\u00ean s\u1ed1 chi\u1ec1u, bi\u1ebfn k\u1ebft qu\u1ea3 th\u00e0nh m\u1ed9t vector c\u1ed9t <code>[[8.395], [7.29], [2.487]]</code> c\u00f3 shape <code>(3, 1)</code>. L\u00fac n\u00e0y, NumPy c\u00f3 th\u1ec3 th\u1ef1c hi\u1ec7n ph\u00e9p chia ma tr\u1eadn <code>(3, 3)</code> cho vector c\u1ed9t <code>(3, 1)</code> m\u1ed9t c\u00e1ch ch\u00ednh x\u00e1c (m\u1ed7i h\u00e0ng c\u1ee7a ma tr\u1eadn \u0111\u01b0\u1ee3c chia cho gi\u00e1 tr\u1ecb t\u01b0\u01a1ng \u1ee9ng trong vector c\u1ed9t).</li> </ul>"},{"location":"Explain%20Documents/03-softmax_explain/#muc-4-bi-kip-chong-tran-so-overflow-prevention","title":"M\u1ee5c 4: \"B\u00ed k\u00edp\" ch\u1ed1ng tr\u00e0n s\u1ed1 (Overflow Prevention)","text":"<p>H\u00e0m m\u0169 <code>e^x</code> t\u0103ng r\u1ea5t nhanh. N\u1ebfu \u0111\u1ea7u v\u00e0o <code>z</code> l\u00e0 m\u1ed9t s\u1ed1 l\u1edbn (v\u00ed d\u1ee5 <code>1000</code>), <code>np.exp(1000)</code> s\u1ebd tr\u1ea3 v\u1ec1 <code>inf</code> (v\u00f4 c\u1ef1c), g\u00e2y ra l\u1ed7i tr\u00e0n s\u1ed1 (overflow) v\u00e0 l\u00e0m h\u1ecfng to\u00e0n b\u1ed9 ph\u00e9p t\u00ednh.</p> <p>Gi\u1ea3i ph\u00e1p: Ch\u00fang ta c\u00f3 th\u1ec3 tr\u1eeb \u0111i m\u1ed9t s\u1ed1 b\u1ea5t k\u1ef3 t\u1eeb t\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u v\u00e0o <code>z</code> m\u00e0 kh\u00f4ng l\u00e0m thay \u0111\u1ed5i k\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng c\u1ee7a Softmax. T\u1ea1i sao? V\u00ec t\u00ednh ch\u1ea5t c\u1ee7a ph\u00e9p l\u0169y th\u1eeba v\u00e0 ph\u00e9p chia: $$ \\frac{e<sup>{z_1}}{e</sup>{z_1} + e^{z_2}} = \\frac{e^{z_1} \\cdot e<sup>{-C}}{e</sup>{z_1} \\cdot e^{-C} + e^{z_2} \\cdot e^{-C}} = \\frac{e^{z_1 - C}}{e^{z_1 - C} + e^{z_2 - C}} $$</p> <p>V\u1eady ch\u00fang ta n\u00ean tr\u1eeb \u0111i s\u1ed1 n\u00e0o? S\u1ed1 l\u1edbn nh\u1ea5t (max) trong c\u00e1c gi\u00e1 tr\u1ecb \u0111\u1ea7u v\u00e0o c\u1ee7a h\u00e0ng \u0111\u00f3.</p> Python<pre><code>inputs = [1, 2, 3]\nmax_value = 3\nshifted_inputs = [1-3, 2-3, 3-3] # -&gt; [-2, -1, 0]\n</code></pre> <p>L\u1ee3i \u00edch c\u1ee7a vi\u1ec7c n\u00e0y: 1.  Gi\u00e1 tr\u1ecb l\u1edbn nh\u1ea5t sau khi tr\u1eeb s\u1ebd l\u00e0 <code>0</code>. (<code>e^0 = 1</code>) 2.  T\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb kh\u00e1c s\u1ebd l\u00e0 s\u1ed1 \u00e2m. (<code>e</code> m\u0169 s\u1ed1 \u00e2m lu\u00f4n l\u00e0 m\u1ed9t s\u1ed1 nh\u1ecf h\u01a1n 1). 3.  \u0110i\u1ec1u n\u00e0y \u0111\u1ea3m b\u1ea3o r\u1eb1ng \u0111\u1ea7u v\u00e0o cho h\u00e0m <code>exp</code> s\u1ebd kh\u00f4ng bao gi\u1edd l\u00e0 m\u1ed9t s\u1ed1 d\u01b0\u01a1ng l\u1edbn, t\u1eeb \u0111\u00f3 ng\u0103n ch\u1eb7n ho\u00e0n to\u00e0n l\u1ed7i tr\u00e0n s\u1ed1.</p> <p>\u0110\u00e2y ch\u00ednh l\u00e0 l\u00fd do trong \u0111o\u1ea1n code cu\u1ed1i c\u00f9ng c\u1ee7a s\u00e1ch, b\u1ea1n s\u1ebd th\u1ea5y d\u00f2ng n\u00e0y: Python<pre><code>exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n</code></pre> \u0110\u00e2y l\u00e0 phi\u00ean b\u1ea3n Softmax ho\u00e0n ch\u1ec9nh, an to\u00e0n v\u00e0 hi\u1ec7u qu\u1ea3.</p>"},{"location":"Explain%20Documents/03-softmax_explain/#phan-2-giai-thich-truu-tuong-de-hieu","title":"Ph\u1ea7n 2: Gi\u1ea3i Th\u00edch Tr\u1eebu T\u01b0\u1ee3ng &amp; D\u1ec5 Hi\u1ec3u","text":"<p>H\u00e3y qu\u00ean \u0111i c\u00f4ng th\u1ee9c to\u00e1n h\u1ecdc v\u00e0 code. H\u00e3y t\u01b0\u1edfng t\u01b0\u1ee3ng Softmax l\u00e0 m\u1ed9t \"M\u00e1y Ph\u00e2n B\u1ed5 S\u1ef1 T\u1ef1 Tin\" cho m\u1ed9t cu\u1ed9c thi t\u00e0i n\u0103ng.</p> <p>1. V\u00f2ng S\u01a1 Kh\u1ea3o - \u0110i\u1ec3m th\u00f4 (Raw Scores)</p> <p>Gi\u1ea3 s\u1eed c\u00f3 3 th\u00ed sinh (Ch\u00f3, M\u00e8o, Chim) tham gia m\u1ed9t cu\u1ed9c thi. Ban gi\u00e1m kh\u1ea3o (l\u1edbp m\u1ea1ng n\u01a1-ron ph\u00eda tr\u01b0\u1edbc) cho \u0111i\u1ec3m th\u00f4. \u0110i\u1ec3m n\u00e0y c\u00f3 th\u1ec3 r\u1ea5t l\u1ed9n x\u1ed9n: <code>\u0110i\u1ec3m th\u00f4 = [4.8, 1.21, 2.385]</code></p> <p>Nh\u00ecn v\u00e0o \u0111i\u1ec3m n\u00e0y, ch\u00fang ta bi\u1ebft th\u00ed sinh Ch\u00f3 c\u00f3 \u0111i\u1ec3m cao nh\u1ea5t, nh\u01b0ng \"cao h\u01a1n\" nh\u01b0 th\u1ebf n\u00e0o? M\u1ee9c \u0111\u1ed9 \"chi\u1ebfn th\u1eafng\" c\u00f3 \u00e1p \u0111\u1ea3o kh\u00f4ng? R\u1ea5t kh\u00f3 n\u00f3i.</p> <p>2. B\u01b0\u1edbc 1: M\u00e1y \"Hype\" - L\u0169y th\u1eeba h\u00f3a</p> <p>\u0110\u1ec3 l\u00e0m cho k\u1ebft qu\u1ea3 r\u00f5 r\u00e0ng h\u01a1n, MC cho c\u00e1c \u0111i\u1ec3m s\u1ed1 n\u00e0y v\u00e0o m\u1ed9t c\u00e1i M\u00e1y \"Hype\". M\u00e1y n\u00e0y c\u00f3 2 ch\u1ee9c n\u0103ng: *   Kh\u00f4ng c\u00f3 \u0111i\u1ec3m \u00e2m: N\u00f3 bi\u1ebfn m\u1ecdi \u0111i\u1ec3m s\u1ed1 th\u00e0nh \u0111i\u1ec3m \"nhi\u1ec7t t\u00ecnh\" (lu\u00f4n d\u01b0\u01a1ng). *   T\u00e2ng b\u1ed1c ng\u01b0\u1eddi gi\u1ecfi nh\u1ea5t: M\u00e1y n\u00e0y c\u1ef1c k\u1ef3 \"thi\u00ean v\u1ecb\". Ai \u0111i\u1ec3m cao s\u1eb5n r\u1ed3i s\u1ebd \u0111\u01b0\u1ee3c t\u00e2ng b\u1ed1c l\u00ean t\u1eadn m\u00e2y xanh, trong khi ng\u01b0\u1eddi \u0111i\u1ec3m th\u1ea5p ch\u1ec9 \u0111\u01b0\u1ee3c t\u0103ng nh\u1eb9.</p> <p>Sau khi qua M\u00e1y \"Hype\" (t\u1ee9c l\u00e0 <code>e^x</code>): <code>\u0110i\u1ec3m Hype = [121.5, 3.4, 10.9]</code></p> <p>B\u00e2y gi\u1edd th\u00ec s\u1ef1 kh\u00e1c bi\u1ec7t \u0111\u00e3 qu\u00e1 r\u00f5 r\u00e0ng! Th\u00ed sinh Ch\u00f3 kh\u00f4ng ch\u1ec9 cao \u0111i\u1ec3m h\u01a1n, m\u00e0 c\u00f2n \u00e1p \u0111\u1ea3o ho\u00e0n to\u00e0n ph\u1ea7n c\u00f2n l\u1ea1i.</p> <p>3. B\u01b0\u1edbc 2: Chia \"Chi\u1ebfc B\u00e1nh T\u1ef1 Tin\" - Chu\u1ea9n h\u00f3a</p> <p>B\u00e2y gi\u1edd, \u0111\u1ec3 kh\u00e1n gi\u1ea3 d\u1ec5 hi\u1ec3u, MC quy\u1ebft \u0111\u1ecbnh kh\u00f4ng d\u00f9ng \u0111i\u1ec3m hype n\u1eefa m\u00e0 s\u1ebd chia m\u1ed9t \"chi\u1ebfc b\u00e1nh t\u1ef1 tin\" 100% cho 3 th\u00ed sinh, d\u1ef1a tr\u00ean t\u1ef7 l\u1ec7 \u0111i\u1ec3m hype c\u1ee7a h\u1ecd.</p> <ul> <li>T\u1ed5ng \u0111i\u1ec3m Hype = 121.5 + 3.4 + 10.9 = 135.8</li> <li>Ph\u1ea7n b\u00e1nh c\u1ee7a Ch\u00f3: <code>121.5 / 135.8 \u2248 89.5%</code></li> <li>Ph\u1ea7n b\u00e1nh c\u1ee7a M\u00e8o: <code>3.4 / 135.8 \u2248 2.5%</code></li> <li>Ph\u1ea7n b\u00e1nh c\u1ee7a Chim: <code>10.9 / 135.8 \u2248 8.0%</code></li> </ul> <p>K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng: <code>M\u1ee9c \u0111\u1ed9 t\u1ef1 tin = [0.895, 0.025, 0.080]</code></p> <p>\u0110\u00e2y ch\u00ednh l\u00e0 \u0111\u1ea7u ra c\u1ee7a Softmax. N\u00f3 cho ch\u00fang ta m\u1ed9t k\u1ebft lu\u1eadn r\u1ea5t r\u00f5 r\u00e0ng: \"D\u1ef1a tr\u00ean m\u00e0n tr\u00ecnh di\u1ec5n, t\u00f4i tin ch\u1eafc 89.5% ng\u01b0\u1eddi chi\u1ebfn th\u1eafng l\u00e0 Ch\u00f3.\"</p> <p>V\u1ec1 \"b\u00ed k\u00edp\" ch\u1ed1ng tr\u00e0n s\u1ed1: H\u00e3y t\u01b0\u1edfng t\u01b0\u1ee3ng m\u1ed9t gi\u00e1m kh\u1ea3o qu\u00e1 ph\u1ea5n kh\u00edch cho \u0111i\u1ec3m <code>1000</code>. M\u00e1y \"Hype\" s\u1ebd b\u1ecb \"ch\u00e1y\" (overflow). MC th\u00f4ng minh nh\u1eadn ra r\u1eb1ng \u0111i\u1ec1u quan tr\u1ecdng l\u00e0 s\u1ef1 ch\u00eanh l\u1ec7ch \u0111i\u1ec3m s\u1ed1 ch\u1ee9 kh\u00f4ng ph\u1ea3i b\u1ea3n th\u00e2n \u0111i\u1ec3m s\u1ed1. V\u00ec v\u1eady, tr\u01b0\u1edbc khi cho v\u00e0o m\u00e1y, anh ta t\u00ecm \u0111i\u1ec3m cao nh\u1ea5t (1000) v\u00e0 tr\u1eeb n\u00f3 kh\u1ecfi \u0111i\u1ec3m c\u1ee7a m\u1ecdi ng\u01b0\u1eddi. K\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng sau khi chia b\u00e1nh v\u1eabn kh\u00f4ng h\u1ec1 thay \u0111\u1ed5i, nh\u01b0ng c\u00e1i m\u00e1y hype \u0111\u00e3 \u0111\u01b0\u1ee3c c\u1ee9u!</p> <p>T\u00f3m l\u1ea1i, Softmax l\u00e0m hai vi\u1ec7c:</p> <ol> <li>S\u1eed d\u1ee5ng h\u00e0m m\u0169 <code>e^x</code> \u0111\u1ec3 khu\u1ebfch \u0111\u1ea1i \u0111i\u1ec3m s\u1ed1 cao nh\u1ea5t, bi\u1ebfn n\u00f3 th\u00e0nh \"ng\u01b0\u1eddi d\u1eabn \u0111\u1ea7u\" r\u00f5 r\u1ec7t.</li> <li>Chu\u1ea9n h\u00f3a c\u00e1c \u0111i\u1ec3m s\u1ed1 \u0111\u00e3 \u0111\u01b0\u1ee3c khu\u1ebfch \u0111\u1ea1i \u0111\u00f3 th\u00e0nh m\u1ed9t t\u1ef7 l\u1ec7 ph\u1ea7n tr\u0103m (ho\u1eb7c x\u00e1c su\u1ea5t), \u0111\u1ec3 t\u1ea5t c\u1ea3 c\u1ed9ng l\u1ea1i b\u1eb1ng 1.</li> </ol>"},{"location":"Explain%20Documents/04-schema_math/","title":"Ch4pt3r.04 - Math Schema","text":""},{"location":"Explain%20Documents/04-schema_math/#i-sau-vao-phong-may-cua-mang-no-ron-va-xem-xet-tung-phep-nhan-phep-cong-ma-tran","title":"\u0110i s\u00e2u v\u00e0o \"ph\u00f2ng m\u00e1y\" c\u1ee7a m\u1ea1ng n\u01a1-ron v\u00e0 xem x\u00e9t t\u1eebng ph\u00e9p nh\u00e2n, ph\u00e9p c\u1ed9ng ma tr\u1eadn","text":"<p>Gi\u1ea3 s\u1eed ch\u00fang ta c\u00f3 m\u1ed9t b\u00e0i to\u00e1n \u0111\u01a1n gi\u1ea3n: *   \u0110\u1ea7u v\u00e0o: M\u1ed9t vector c\u00f3 2 \u0111\u1eb7c tr\u01b0ng (v\u00ed d\u1ee5: chi\u1ec1u cao, c\u00e2n n\u1eb7ng). *   Ki\u1ebfn tr\u00fac m\u1ea1ng:     *   L\u1edbp \u1ea9n (Hidden Layer) c\u00f3 3 neuron.     *   L\u1edbp ra (Output Layer) c\u00f3 2 neuron (t\u01b0\u01a1ng \u1ee9ng 2 l\u1edbp, v\u00ed d\u1ee5: \"Lo\u1ea1i A\" v\u00e0 \"Lo\u1ea1i B\"). *   H\u00e0m k\u00edch ho\u1ea1t: ReLU cho l\u1edbp \u1ea9n, Softmax cho l\u1edbp ra.</p> <p>H\u00e3y b\u1eaft \u0111\u1ea7u v\u1edbi c\u00e1c gi\u00e1 tr\u1ecb c\u1ee5 th\u1ec3.</p>"},{"location":"Explain%20Documents/04-schema_math/#so-o-chi-tiet-tung-buoc-tinh-toan-ma-tran","title":"S\u01a1 \u0110\u1ed3 Chi Ti\u1ebft: T\u1eebng B\u01b0\u1edbc T\u00ednh To\u00e1n Ma Tr\u1eadn","text":"<p>B\u01b0\u1edbc 0: Kh\u1edfi t\u1ea1o c\u00e1c tham s\u1ed1</p> <ul> <li> <p>D\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o (m\u1ed9t m\u1eabu): <code>inputs = [1, 2]</code>  (shape: 1x2)</p> </li> <li> <p>Tr\u1ecdng s\u1ed1 v\u00e0 bias L\u1edbp \u1ea8n (W1, b1): <code>W1 = [[0.2, 0.8, -0.5],</code> <code>[0.5, -0.9, 0.3]]</code> (shape: 2x3)</p> <p><code>b1 = [2, 3, 0.5]</code> (shape: 1x3)</p> </li> <li> <p>Tr\u1ecdng s\u1ed1 v\u00e0 bias L\u1edbp Ra (W2, b2): <code>W2 = [[0.1, -0.4],</code> <code>[-0.2, 0.6],</code> <code>[0.7, -0.9]]</code> (shape: 3x2)</p> <p><code>b2 = [0.1, -0.2]</code> (shape: 1x2)</p> </li> </ul> <p>B\u01b0\u1edbc 1: T\u00ednh to\u00e1n t\u1ea1i L\u1edbp \u1ea8n (Hidden Layer)</p> <p>Ph\u00e9p to\u00e1n: <code>z1 = inputs \u00b7 W1 + b1</code> (Ph\u00e9p nh\u00e2n ma tr\u1eadn <code>\u00b7</code> v\u00e0 c\u1ed9ng vector)</p> Text Only<pre><code>        [ Tr\u1ecdng s\u1ed1 W1 ]\n         (shape 2x3)\n      [[0.2, 0.8, -0.5],\n       [0.5, -0.9, 0.3]]\n            ^\n            |\n[inputs] \u00b7--+\n(1x2)\n[1, 2]\n\n================== Ph\u00e9p nh\u00e2n ma tr\u1eadn (inputs \u00b7 W1) ==================\n\nK\u1ebft qu\u1ea3 (1x3) = [(1*0.2 + 2*0.5), (1*0.8 + 2*-0.9), (1*-0.5 + 2*0.3)]\n              = [(0.2 + 1.0),   (0.8 - 1.8),    (-0.5 + 0.6)  ]\n              = [1.2,           -1.0,           0.1           ]\n\n================== Ph\u00e9p c\u1ed9ng bias ( + b1 ) =======================\n\n  [1.2, -1.0, 0.1]\n+ [2.0,  3.0, 0.5]\n--------------------\n= [3.2,  2.0, 0.6]  &lt;== \u0110\u00e2y l\u00e0 z1 (logits c\u1ee7a l\u1edbp \u1ea9n)\n</code></pre> <p>B\u01b0\u1edbc 2: \u00c1p d\u1ee5ng h\u00e0m k\u00edch ho\u1ea1t ReLU</p> <p>Ph\u00e9p to\u00e1n: <code>h1 = ReLU(z1) = max(0, z1)</code></p> Text Only<pre><code>  Input v\u00e0o ReLU: z1 = [3.2, 2.0, 0.6]\n\n  max(0, 3.2) -&gt; 3.2\n  max(0, 2.0) -&gt; 2.0\n  max(0, 0.6) -&gt; 0.6\n\n  K\u1ebft qu\u1ea3: h1 = [3.2, 2.0, 0.6] &lt;== \u0110\u1ea7u ra c\u1ee7a l\u1edbp \u1ea9n sau k\u00edch ho\u1ea1t\n  (Trong tr\u01b0\u1eddng h\u1ee3p n\u00e0y kh\u00f4ng c\u00f3 gi\u00e1 tr\u1ecb n\u00e0o b\u1ecb c\u1eaft v\u00ec t\u1ea5t c\u1ea3 \u0111\u1ec1u d\u01b0\u01a1ng)\n</code></pre> <p>B\u01b0\u1edbc 3: T\u00ednh to\u00e1n t\u1ea1i L\u1edbp Ra (Output Layer)</p> <p>Ph\u00e9p to\u00e1n: <code>z_out = h1 \u00b7 W2 + b2</code></p> Text Only<pre><code>        [ Tr\u1ecdng s\u1ed1 W2 ]\n         (shape 3x2)\n      [[0.1, -0.4],\n       [-0.2, 0.6],\n       [0.7, -0.9]]\n            ^\n            |\n   [h1] \u00b7---+\n  (1x3)\n[3.2, 2.0, 0.6]\n\n================== Ph\u00e9p nh\u00e2n ma tr\u1eadn (h1 \u00b7 W2) =====================\n\nK\u1ebft qu\u1ea3 (1x2) = [ (3.2*0.1 + 2.0*-0.2 + 0.6*0.7),  (3.2*-0.4 + 2.0*0.6 + 0.6*-0.9) ]\n              = [ (0.32  - 0.4    + 0.42),       (-1.28    + 1.2    - 0.54)       ]\n              = [ 0.34,                          -0.62                         ]\n\n================== Ph\u00e9p c\u1ed9ng bias ( + b2 ) ========================\n\n  [0.34, -0.62]\n+ [0.1,  -0.2]\n--------------------\n= [0.44, -0.82] &lt;== \u0110\u00e2y l\u00e0 z_out (logits cu\u1ed1i c\u00f9ng tr\u01b0\u1edbc Softmax)\n</code></pre> <p>B\u01b0\u1edbc 4: \u00c1p d\u1ee5ng h\u00e0m k\u00edch ho\u1ea1t Softmax</p> <p>Ph\u00e9p to\u00e1n: <code>probabilities = Softmax(z_out)</code></p> <ol> <li> <p>L\u0169y th\u1eeba h\u00f3a: <code>e^z_out</code> <code>e^0.44  \u2248 1.55</code> <code>e^-0.82 \u2248 0.44</code></p> </li> <li> <p>T\u00ednh t\u1ed5ng: <code>T\u1ed5ng = 1.55 + 0.44 = 1.99</code></p> </li> <li> <p>Chu\u1ea9n h\u00f3a: <code>X\u00e1c su\u1ea5t L\u1edbp A = 1.55 / 1.99 \u2248 0.779</code> <code>X\u00e1c su\u1ea5t L\u1edbp B = 0.44 / 1.99 \u2248 0.221</code></p> </li> </ol>"},{"location":"Explain%20Documents/04-schema_math/#ket-qua-cuoi-cung","title":"K\u1ebeT QU\u1ea2 CU\u1ed0I C\u00d9NG","text":"Text Only<pre><code>  Input: [1, 2]\n    |\n    V\n  z1 = [3.2, 2.0, 0.6]  (Sau L\u1edbp \u1ea8n 1)\n    |\n    V (ReLU)\n  h1 = [3.2, 2.0, 0.6]\n    |\n    V\n  z_out = [0.44, -0.82] (Sau L\u1edbp Ra)\n    |\n    V (Softmax)\n  Probabilities = [0.779, 0.221]\n\n==&gt; D\u1ef1 \u0111o\u00e1n: \"Lo\u1ea1i A\" v\u1edbi x\u00e1c su\u1ea5t 77.9%\n</code></pre> <p>S\u01a1 \u0111\u1ed3 chi ti\u1ebft n\u00e0y cho th\u1ea5y ch\u00ednh x\u00e1c c\u00e1ch m\u1ed9t vector \u0111\u1ea7u v\u00e0o <code>[1, 2]</code> \u0111i qua t\u1eebng l\u1edbp, qua t\u1eebng ph\u00e9p nh\u00e2n ma tr\u1eadn, c\u1ed9ng bias v\u00e0 h\u00e0m k\u00edch ho\u1ea1t \u0111\u1ec3 cu\u1ed1i c\u00f9ng cho ra m\u1ed9t d\u1ef1 \u0111o\u00e1n x\u00e1c su\u1ea5t c\u1ee5 th\u1ec3. M\u1ed7i b\u01b0\u1edbc \u0111\u1ec1u l\u00e0 m\u1ed9t ph\u00e9p to\u00e1n ma tr\u1eadn ho\u1eb7c vector \u0111\u01a1n gi\u1ea3n. Qu\u00e1 tr\u00ecnh \"h\u1ecdc\" c\u1ee7a m\u1ea1ng n\u01a1-ron ch\u00ednh l\u00e0 vi\u1ec7c \u0111i\u1ec1u ch\u1ec9nh c\u00e1c gi\u00e1 tr\u1ecb trong ma tr\u1eadn <code>W1, b1, W2, b2</code> \u0111\u1ec3 k\u1ebft qu\u1ea3 cu\u1ed1i c\u00f9ng ng\u00e0y c\u00e0ng ch\u00ednh x\u00e1c.</p>"}]}